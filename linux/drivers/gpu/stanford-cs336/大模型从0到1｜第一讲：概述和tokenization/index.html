

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicon.jpg">
  <link rel="icon" href="/images/favicon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Wu Jing">
  <meta name="keywords" content="3d, Linux-0.11-yuan-xy, ThreadPool, acpi, algorithm, architect, assembly, baohua, binary-analysis, books, boot, bpf, bugs, ceph, cmake-objdump, console, container, cpp, dbus, deb, debug, deepin, develop, disk, distro, docker, drivers, extern, fluid, fs, gdb, git, go, gpu, grtrace, grub, hello_world, hexo, irq, java, javascript, jenkins, k8s, kdump, kernel, kickstart, kms, kvm, linux, linux-0.11-debug, log, ltp, markdown, minifs, mm, modules, monitoring, mutex, my-project, net, nginx, patent, perf, perf-event, performance, phytium, pkg, port-forward, power, proc, protobuf, protobuf_example, proxy, pthread, pulseaudio, python, qemu, qprocess_wget, qt-learning, rcu, redis, rpm-ostree, runoob-vue3-test, security, shell, sound, sources, stanford-cs336, stap, struct, svn, sync, sysrq_trigger, task, testing, thread, tick, todolist, tools, udl, unixbench, uts_namespace, valgrind, vim, virsh, virt, xisai">
  
    <meta name="description" content="大模型从0到1｜第一讲：概述和Tokenization 课程链接：Stanford CS336 Spring 2025 - Lecture 1   课程团队 CS336: Language Models From Scratch (Spring 2025)  这是 CS336 的第二次开课 斯坦福版本规模扩大了 50% 讲座将发布到 YouTube，向全世界开放   为什么要开设这门课？问题：研究">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型从0到1｜第一讲：概述和Tokenization">
<meta property="og:url" content="https://realwujing.github.io/linux/drivers/gpu/stanford-cs336/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8E0%E5%88%B01%EF%BD%9C%E7%AC%AC%E4%B8%80%E8%AE%B2%EF%BC%9A%E6%A6%82%E8%BF%B0%E5%92%8Ctokenization/index.html">
<meta property="og:site_name" content="WuJing&#39;s Blog">
<meta property="og:description" content="大模型从0到1｜第一讲：概述和Tokenization 课程链接：Stanford CS336 Spring 2025 - Lecture 1   课程团队 CS336: Language Models From Scratch (Spring 2025)  这是 CS336 的第二次开课 斯坦福版本规模扩大了 50% 讲座将发布到 YouTube，向全世界开放   为什么要开设这门课？问题：研究">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/course-staff.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Industrialisation.jpg/440px-Industrialisation.jpg">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/gpt4-no-details.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/roller-flops.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/wei-emergence-plot.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/divine-benevolence.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/design-decisions.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/tokenized-example.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/transformer-architecture.png">
<meta property="og:image" content="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*6xoBKi5kL2dZpivFe1-zgw.jpeg">
<meta property="og:image" content="https://horace.io/img/perf_intro/factory_bandwidth.png">
<meta property="og:image" content="https://www.fibermall.com/blog/wp-content/uploads/2024/09/the-hardware-topology-of-a-typical-8xA100-GPU-host.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/prefill-decode.png">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/chinchilla-isoflop.png">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/html/2101.00027/assets/pile_chart2.png">
<meta property="article:published_time" content="2025-11-22T23:22:50.000Z">
<meta property="article:modified_time" content="2025-12-15T17:54:58.000Z">
<meta property="article:author" content="Wu Jing">
<meta property="article:tag" content="architect">
<meta property="article:tag" content="git">
<meta property="article:tag" content="go">
<meta property="article:tag" content="gpu">
<meta property="article:tag" content="kernel">
<meta property="article:tag" content="log">
<meta property="article:tag" content="perf">
<meta property="article:tag" content="python">
<meta property="article:tag" content="sources">
<meta property="article:tag" content="net">
<meta property="article:tag" content="struct">
<meta property="article:tag" content="mm">
<meta property="article:tag" content="stanford-cs336">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://stanford-cs336.github.io/spring2025-lectures/images/course-staff.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>大模型从0到1｜第一讲：概述和Tokenization - WuJing&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/custom.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"realwujing.github.io","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"6b5123e146041483d13bdfaeb6e42a76","google":"UA-265632133-1","gtag":"G-E7BV6T4RCW","tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?6b5123e146041483d13bdfaeb6e42a76";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  
    <!-- Google Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('https://www.google-analytics.com/analytics.js', function() {
          window.ga = window.ga || function() { (ga.q = ga.q || []).push(arguments) };
          ga.l = +new Date;
          ga('create', 'UA-265632133-1', 'auto');
          ga('send', 'pageview');
        });
      }
    </script>
  

  
    <!-- Google gtag.js -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('https://www.googletagmanager.com/gtag/js?id=G-E7BV6T4RCW', function() {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-E7BV6T4RCW');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>WuJing&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="大模型从0到1｜第一讲：概述和Tokenization"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-11-22 23:22" pubdate>
          2025年11月22日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          110 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">大模型从0到1｜第一讲：概述和Tokenization</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2025年12月15日 下午
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="大模型从0到1｜第一讲：概述和Tokenization"><a href="#大模型从0到1｜第一讲：概述和Tokenization" class="headerlink" title="大模型从0到1｜第一讲：概述和Tokenization"></a>大模型从0到1｜第一讲：概述和Tokenization</h1><blockquote>
<p>课程链接：<a target="_blank" rel="noopener" href="https://stanford-cs336.github.io/spring2025-lectures/?trace=var/traces/lecture_01.json">Stanford CS336 Spring 2025 - Lecture 1</a></p>
</blockquote>
<hr>
<h2 id="课程团队"><a href="#课程团队" class="headerlink" title="课程团队"></a>课程团队</h2><p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/course-staff.png" srcset="/img/loading.gif" lazyload alt="Course Staff"></p>
<p><strong>CS336: Language Models From Scratch (Spring 2025)</strong></p>
<ul>
<li>这是 CS336 的第二次开课</li>
<li>斯坦福版本规模扩大了 50%</li>
<li>讲座将发布到 YouTube，向全世界开放</li>
</ul>
<hr>
<h2 id="为什么要开设这门课？"><a href="#为什么要开设这门课？" class="headerlink" title="为什么要开设这门课？"></a>为什么要开设这门课？</h2><h3 id="问题：研究者与底层技术的脱节"><a href="#问题：研究者与底层技术的脱节" class="headerlink" title="问题：研究者与底层技术的脱节"></a>问题：研究者与底层技术的脱节</h3><p>让我们问问 GPT-4：</p>
<blockquote>
<p>“Why teach a course on building language models from scratch? Answer in one sentence.”</p>
</blockquote>
<p><strong>核心问题：</strong> 研究者正在与底层技术<strong>脱节</strong></p>
<p><strong>时间线：</strong></p>
<ul>
<li><strong>8 年前：</strong> 研究者会实现并训练自己的模型</li>
<li><strong>6 年前：</strong> 研究者会下载模型（如 BERT）并微调</li>
<li><strong>今天：</strong> 研究者只是提示专有模型（GPT-4&#x2F;Claude&#x2F;Gemini）</li>
</ul>
<p><strong>抽象层次的提升：</strong></p>
<ul>
<li>✅ 提高生产力</li>
<li>❌ 但这些抽象是有漏洞的（与编程语言或操作系统不同）</li>
<li>❌ 仍有需要撕开整个技术栈的基础研究</li>
</ul>
<p><strong>核心理念：</strong> 对这项技术的<strong>完全理解</strong>对于<strong>基础研究</strong>是必要的</p>
<p><strong>本课程方法：</strong> 通过<strong>构建</strong>来<strong>理解</strong></p>
<p>但有一个小问题…</p>
<hr>
<h2 id="大模型的工业化"><a href="#大模型的工业化" class="headerlink" title="大模型的工业化"></a>大模型的工业化</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Industrialisation.jpg/440px-Industrialisation.jpg" srcset="/img/loading.gif" lazyload alt="Industrialization"></p>
<p><strong>规模现状：</strong></p>
<ul>
<li>GPT-4 据称有 1.8T 参数</li>
<li>GPT-4 据称训练成本 $100M</li>
<li>xAI 用 200,000 个 H100 构建集群训练 Grok</li>
<li>Stargate（OpenAI, NVIDIA, Oracle）4 年投资 $500B</li>
</ul>
<p><strong>透明度问题：</strong></p>
<p>没有关于前沿模型如何构建的公开细节。</p>
<p>来自 GPT-4 技术报告：</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/gpt4-no-details.png" srcset="/img/loading.gif" lazyload alt="GPT-4 No Details"></p>
<hr>
<h2 id="More-is-Different（规模带来质变）"><a href="#More-is-Different（规模带来质变）" class="headerlink" title="More is Different（规模带来质变）"></a>More is Different（规模带来质变）</h2><p><strong>挑战：</strong></p>
<ul>
<li>前沿模型对我们来说遥不可及</li>
<li>构建小型语言模型（&lt;1B 参数）可能无法代表大型语言模型</li>
</ul>
<p><strong>示例 1：</strong> 注意力 vs MLP 的 FLOPs 占比随规模变化</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/roller-flops.png" srcset="/img/loading.gif" lazyload alt="Roller FLOPs"></p>
<p><strong>示例 2：</strong> 行为的涌现（Emergence）</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/wei-emergence-plot.png" srcset="/img/loading.gif" lazyload alt="Wei Emergence"></p>
<hr>
<h2 id="本课程能学到什么可以迁移到前沿模型？"><a href="#本课程能学到什么可以迁移到前沿模型？" class="headerlink" title="本课程能学到什么可以迁移到前沿模型？"></a>本课程能学到什么可以迁移到前沿模型？</h2><p><strong>三类知识：</strong></p>
<ol>
<li><p><strong>机制（Mechanics）：</strong> 事物如何工作</p>
<ul>
<li>Transformer 是什么</li>
<li>模型并行如何利用 GPU</li>
<li>✅ <strong>可迁移</strong></li>
</ul>
</li>
<li><p><strong>思维方式（Mindset）：</strong> 充分利用硬件，认真对待规模</p>
<ul>
<li>扩展定律（Scaling Laws）</li>
<li>✅ <strong>可迁移</strong></li>
</ul>
</li>
<li><p><strong>直觉（Intuitions）：</strong> 哪些数据和建模决策产生好的准确性</p>
<ul>
<li>⚠️ <strong>部分可迁移</strong>（不一定跨规模迁移）</li>
</ul>
</li>
</ol>
<hr>
<h2 id="直觉？🤷"><a href="#直觉？🤷" class="headerlink" title="直觉？🤷"></a>直觉？🤷</h2><p><strong>现实：</strong> 一些设计决策无法（尚未）证明合理性，只能来自实验</p>
<p><strong>示例：</strong> Noam Shazeer 引入 SwiGLU 的论文</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/divine-benevolence.png" srcset="/img/loading.gif" lazyload alt="Divine Benevolence"></p>
<hr>
<h2 id="The-Bitter-Lesson（痛苦的教训）"><a href="#The-Bitter-Lesson（痛苦的教训）" class="headerlink" title="The Bitter Lesson（痛苦的教训）"></a>The Bitter Lesson（痛苦的教训）</h2><p><strong>错误解读：</strong> 规模就是一切，算法不重要</p>
<p><strong>正确解读：</strong> 能够扩展的算法才重要</p>
<h3 id="accuracy-efficiency-×-resources"><a href="#accuracy-efficiency-×-resources" class="headerlink" title="accuracy &#x3D; efficiency × resources"></a>accuracy &#x3D; efficiency × resources</h3><p><strong>效率的重要性：</strong></p>
<ul>
<li>在更大规模下，效率更加重要（不能浪费）</li>
<li>2012-2019 年，ImageNet 上的算法效率提升了 44 倍</li>
</ul>
<p><strong>框架：</strong> 给定一定的计算和数据预算，能构建的最佳模型是什么？</p>
<p>换句话说，<strong>最大化效率</strong>！</p>
<hr>
<h2 id="大模型发展历程"><a href="#大模型发展历程" class="headerlink" title="大模型发展历程"></a>大模型发展历程</h2><h3 id="前神经网络时代（2010年代之前）"><a href="#前神经网络时代（2010年代之前）" class="headerlink" title="前神经网络时代（2010年代之前）"></a>前神经网络时代（2010年代之前）</h3><ul>
<li><strong>语言模型测量英语熵</strong> - Shannon (1950)</li>
<li><strong>N-gram 语言模型</strong> - 用于机器翻译、语音识别 - Brants et al. (2007)</li>
</ul>
<h3 id="神经网络组件（2010年代）"><a href="#神经网络组件（2010年代）" class="headerlink" title="神经网络组件（2010年代）"></a>神经网络组件（2010年代）</h3><ul>
<li><strong>首个神经语言模型</strong> - Bengio et al. (2003)</li>
<li><strong>序列到序列建模</strong> - 用于机器翻译 - Sutskever et al. (2014)</li>
<li><strong>Adam 优化器</strong> - Kingma &amp; Ba (2014)</li>
<li><strong>注意力机制</strong> - 用于机器翻译 - Bahdanau et al. (2015)</li>
<li><strong>Transformer 架构</strong> - 用于机器翻译 - Vaswani et al. (2017)</li>
<li><strong>混合专家（MoE）</strong> - Shazeer et al. (2017)</li>
<li><strong>模型并行</strong> - GPipe (2018), ZeRO (2019), Megatron-LM (2019)</li>
</ul>
<h3 id="早期基础模型（2010年代末）"><a href="#早期基础模型（2010年代末）" class="headerlink" title="早期基础模型（2010年代末）"></a>早期基础模型（2010年代末）</h3><ul>
<li><strong>ELMo：</strong> LSTM 预训练，微调帮助任务</li>
<li><strong>BERT：</strong> Transformer 预训练，微调帮助任务</li>
<li><strong>Google T5 (11B)：</strong> 将一切转换为文本到文本</li>
</ul>
<h3 id="拥抱规模，更加封闭"><a href="#拥抱规模，更加封闭" class="headerlink" title="拥抱规模，更加封闭"></a>拥抱规模，更加封闭</h3><ul>
<li><strong>OpenAI GPT-2 (1.5B)：</strong> 流畅文本，零样本的初步迹象，分阶段发布</li>
<li><strong>扩展定律：</strong> 为扩展提供希望&#x2F;可预测性 - Kaplan et al. (2020)</li>
<li><strong>OpenAI GPT-3 (175B)：</strong> 上下文学习，封闭</li>
<li><strong>Google PaLM (540B)：</strong> 大规模，训练不足</li>
<li><strong>DeepMind Chinchilla (70B)：</strong> 计算最优扩展定律</li>
</ul>
<h3 id="开源模型"><a href="#开源模型" class="headerlink" title="开源模型"></a>开源模型</h3><ul>
<li><strong>EleutherAI：</strong> 开放数据集（The Pile）和模型（GPT-J）</li>
<li><strong>Meta OPT (175B)：</strong> GPT-3 复制，许多硬件问题</li>
<li><strong>Hugging Face &#x2F; BigScience BLOOM：</strong> 专注于数据来源</li>
<li><strong>Meta Llama 系列：</strong> Llama, Llama 2, Llama 3</li>
<li><strong>Alibaba Qwen 系列：</strong> Qwen 2.5</li>
<li><strong>DeepSeek 系列：</strong> DeepSeek 67B, DeepSeek-V2, DeepSeek-V3</li>
<li><strong>AI2 OLMo 2：</strong> OLMo 7B, OLMo 2</li>
</ul>
<h3 id="开放程度的层次"><a href="#开放程度的层次" class="headerlink" title="开放程度的层次"></a>开放程度的层次</h3><ol>
<li><strong>封闭模型（如 GPT-4o）：</strong> 仅 API 访问</li>
<li><strong>开放权重模型（如 DeepSeek）：</strong> 权重可用，论文有架构细节，一些训练细节，无数据细节</li>
<li><strong>开源模型（如 OLMo）：</strong> 权重和数据可用，论文有大部分细节（但不一定有理由、失败实验）</li>
</ol>
<h3 id="当今的前沿模型"><a href="#当今的前沿模型" class="headerlink" title="当今的前沿模型"></a>当今的前沿模型</h3><ul>
<li><strong>OpenAI o3</strong></li>
<li><strong>Anthropic Claude Sonnet 3.7</strong></li>
<li><strong>xAI Grok 3</strong></li>
<li><strong>Google Gemini 2.5</strong></li>
<li><strong>Meta Llama 3.3</strong></li>
<li><strong>DeepSeek r1</strong></li>
<li><strong>Alibaba Qwen 2.5 Max</strong></li>
<li><strong>Tencent Hunyuan-T1</strong></li>
</ul>
<hr>
<h2 id="什么是可执行讲座？"><a href="#什么是可执行讲座？" class="headerlink" title="什么是可执行讲座？"></a>什么是可执行讲座？</h2><p>这是一个<strong>可执行讲座</strong>，一个通过执行来传递讲座内容的程序。</p>
<p><strong>可执行讲座的优势：</strong></p>
<ul>
<li>查看和运行代码（因为一切都是代码！）</li>
<li>查看变量值和执行流程</li>
<li>看到讲座的层次结构</li>
<li>跳转到定义和概念</li>
</ul>
<p><strong>示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">total = <span class="hljs-number">0</span>  <span class="hljs-comment"># 可以检查值</span><br><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]:  <span class="hljs-comment"># 可以看到 x 的变化</span><br>    total += x  <span class="hljs-comment"># 可以看到 total 的更新</span><br></code></pre></td></tr></table></figure>

<hr>
<h2 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h2><p><strong>官网：</strong> <a target="_blank" rel="noopener" href="https://stanford-cs336.github.io/spring2025/">https://stanford-cs336.github.io/spring2025/</a></p>
<p><strong>学分：</strong> 5 个学分</p>
<p><strong>工作量警告：</strong></p>
<blockquote>
<p>来自 2024 年春季课程评估的评论：<br>“整个作业的工作量大约相当于 CS 224n 的所有 5 个作业加上最终项目。而这只是第一个作业。”</p>
</blockquote>
<h3 id="为什么应该选这门课"><a href="#为什么应该选这门课" class="headerlink" title="为什么应该选这门课"></a>为什么应该选这门课</h3><ul>
<li>你有强迫性需要理解事物如何工作</li>
<li>你想锻炼研究工程能力</li>
</ul>
<h3 id="为什么不应该选这门课"><a href="#为什么不应该选这门课" class="headerlink" title="为什么不应该选这门课"></a>为什么不应该选这门课</h3><ul>
<li>你这个季度实际上想完成研究（和你的导师谈谈）</li>
<li>你对学习 AI 最新技术感兴趣（如多模态、RAG 等）→ 应该选研讨课</li>
<li>你想在自己的应用领域获得好结果 → 应该提示或微调现有模型</li>
</ul>
<h3 id="如何在家跟随"><a href="#如何在家跟随" class="headerlink" title="如何在家跟随"></a>如何在家跟随</h3><ul>
<li>所有讲座材料和作业将在线发布</li>
<li>讲座通过 CGOE 录制并在 YouTube 上提供（有一定延迟）</li>
<li>我们计划明年再次开设这门课</li>
</ul>
<h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><ul>
<li><strong>5 个作业：</strong> 基础、系统、扩展定律、数据、对齐</li>
<li><strong>无脚手架代码：</strong> 但提供单元测试和适配器接口帮助检查正确性</li>
<li><strong>本地实现测试正确性，然后在集群上运行进行基准测试</strong>（准确性和速度）</li>
<li><strong>排行榜：</strong> 某些作业（在训练预算下最小化困惑度）</li>
<li><strong>AI 工具：</strong> CoPilot、Cursor 可能会影响学习，自行承担风险</li>
</ul>
<h3 id="计算集群"><a href="#计算集群" class="headerlink" title="计算集群"></a>计算集群</h3><ul>
<li>感谢 Together AI 提供计算集群 🙏</li>
<li>请阅读<a target="_blank" rel="noopener" href="https://docs.google.com/document/d/1BSSig7zInyjDKcbNGftVxubiHlwJ-ZqahQewIzBmBOo/edit">使用指南</a></li>
<li><strong>提前开始作业</strong>，因为临近截止日期集群会很满！</li>
</ul>
<hr>
<h2 id="课程核心：效率"><a href="#课程核心：效率" class="headerlink" title="课程核心：效率"></a>课程核心：效率</h2><p><strong>资源：</strong> 数据 + 硬件（计算、内存、通信带宽）</p>
<p><strong>核心问题：</strong> 给定固定资源，如何训练最佳模型？</p>
<p><strong>示例：</strong> 给定 Common Crawl 数据和 32 个 H100 GPU 2 周时间，应该怎么做？</p>
<h3 id="设计决策"><a href="#设计决策" class="headerlink" title="设计决策"></a>设计决策</h3><p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/design-decisions.png" srcset="/img/loading.gif" lazyload alt="Design Decisions"></p>
<hr>
<h2 id="课程概览"><a href="#课程概览" class="headerlink" title="课程概览"></a>课程概览</h2><h3 id="Part-1-基础（Basics）"><a href="#Part-1-基础（Basics）" class="headerlink" title="Part 1: 基础（Basics）"></a>Part 1: 基础（Basics）</h3><p><strong>目标：</strong> 让完整流程的基本版本运行起来</p>
<p><strong>组件：</strong> Tokenization, 模型架构, 训练</p>
<h4 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h4><p>Tokenizer 在字符串和整数序列（token）之间转换</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/tokenized-example.png" srcset="/img/loading.gif" lazyload alt="Tokenized Example"></p>
<p><strong>直觉：</strong> 将字符串分解为流行的片段</p>
<p><strong>本课程：</strong> Byte-Pair Encoding (BPE) tokenizer</p>
<p><strong>无 Tokenizer 方法：</strong> ByT5, MEGABYTE, BLT, TFree</p>
<ul>
<li>直接使用字节，有前景，但尚未扩展到前沿</li>
</ul>
<h4 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h4><p><strong>起点：</strong> 原始 Transformer</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/transformer-architecture.png" srcset="/img/loading.gif" lazyload alt="Transformer Architecture"></p>
<p><strong>变体：</strong></p>
<ul>
<li><strong>激活函数：</strong> ReLU, SwiGLU</li>
<li><strong>位置编码：</strong> Sinusoidal, RoPE</li>
<li><strong>归一化：</strong> LayerNorm, RMSNorm</li>
<li><strong>归一化位置：</strong> Pre-norm vs Post-norm</li>
<li><strong>MLP：</strong> Dense, Mixture of Experts</li>
<li><strong>注意力：</strong> Full, Sliding Window, Linear</li>
<li><strong>低维注意力：</strong> Group-Query Attention (GQA), Multi-Head Latent Attention (MLA)</li>
<li><strong>状态空间模型：</strong> Hyena</li>
</ul>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><ul>
<li><strong>优化器：</strong> AdamW, Muon, SOAP</li>
<li><strong>学习率调度：</strong> Cosine, WSD</li>
<li><strong>批大小：</strong> Critical batch size</li>
<li><strong>正则化：</strong> Dropout, Weight Decay</li>
<li><strong>超参数：</strong> 网格搜索（头数、隐藏维度）</li>
</ul>
<h4 id="Assignment-1"><a href="#Assignment-1" class="headerlink" title="Assignment 1"></a>Assignment 1</h4><p><strong>GitHub：</strong> <a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/assignment1-basics">https://github.com/stanford-cs336/assignment1-basics</a></p>
<p><strong>任务：</strong></p>
<ul>
<li>实现 BPE tokenizer</li>
<li>实现 Transformer、交叉熵损失、AdamW 优化器、训练循环</li>
<li>在 TinyStories 和 OpenWebText 上训练</li>
<li>排行榜：在 H100 上 90 分钟内最小化 OpenWebText 困惑度</li>
</ul>
<hr>
<h3 id="Part-2-系统（Systems）"><a href="#Part-2-系统（Systems）" class="headerlink" title="Part 2: 系统（Systems）"></a>Part 2: 系统（Systems）</h3><p><strong>目标：</strong> 充分利用硬件</p>
<p><strong>组件：</strong> Kernels, 并行化, 推理</p>
<h4 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h4><p><strong>A100 GPU 架构：</strong></p>
<p><img src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*6xoBKi5kL2dZpivFe1-zgw.jpeg" srcset="/img/loading.gif" lazyload alt="A100 Architecture"></p>
<p><strong>类比：</strong> 仓库 : DRAM :: 工厂 : SRAM</p>
<p><img src="https://horace.io/img/perf_intro/factory_bandwidth.png" srcset="/img/loading.gif" lazyload alt="Factory Bandwidth"></p>
<p><strong>技巧：</strong> 通过最小化数据移动来最大化 GPU 利用率</p>
<p><strong>工具：</strong> CUDA &#x2F; <strong>Triton</strong> &#x2F; CUTLASS &#x2F; ThunderKittens</p>
<h4 id="并行化"><a href="#并行化" class="headerlink" title="并行化"></a>并行化</h4><p><strong>多 GPU 场景（8 个 A100）：</strong></p>
<p><img src="https://www.fibermall.com/blog/wp-content/uploads/2024/09/the-hardware-topology-of-a-typical-8xA100-GPU-host.png" srcset="/img/loading.gif" lazyload alt="8xA100 Topology"></p>
<p><strong>原则：</strong> GPU 间数据移动更慢，但同样的”最小化数据移动”原则适用</p>
<p><strong>技术：</strong></p>
<ul>
<li>集合操作（gather, reduce, all-reduce）</li>
<li>跨 GPU 分片（参数、激活、梯度、优化器状态）</li>
<li>并行策略：数据并行、张量并行、流水线并行、序列并行</li>
</ul>
<h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h4><p><strong>目标：</strong> 给定提示生成 token（实际使用模型所需！）</p>
<p><strong>用途：</strong> 强化学习、测试时计算、评估</p>
<p><strong>全局视角：</strong> 推理计算（每次使用）超过训练计算（一次性成本）</p>
<p><strong>两个阶段：</strong></p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/prefill-decode.png" srcset="/img/loading.gif" lazyload alt="Prefill Decode"></p>
<ul>
<li><strong>Prefill（类似训练）：</strong> Token 已给定，可一次处理（计算受限）</li>
<li><strong>Decode：</strong> 需要逐个生成 token（内存受限）</li>
</ul>
<p><strong>加速解码方法：</strong></p>
<ul>
<li>使用更便宜的模型（剪枝、量化、蒸馏）</li>
<li>推测解码：使用便宜的”草稿”模型生成多个 token，然后用完整模型并行评分（精确解码！）</li>
<li>系统优化：KV 缓存、批处理</li>
</ul>
<h4 id="Assignment-2"><a href="#Assignment-2" class="headerlink" title="Assignment 2"></a>Assignment 2</h4><p><strong>GitHub（2024）：</strong> <a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/spring2024-assignment2-systems">https://github.com/stanford-cs336/spring2024-assignment2-systems</a></p>
<p><strong>任务：</strong></p>
<ul>
<li>用 Triton 实现融合 RMSNorm kernel</li>
<li>实现分布式数据并行训练</li>
<li>实现优化器状态分片</li>
<li>对实现进行基准测试和性能分析</li>
</ul>
<hr>
<h3 id="Part-3-扩展定律（Scaling-Laws）"><a href="#Part-3-扩展定律（Scaling-Laws）" class="headerlink" title="Part 3: 扩展定律（Scaling Laws）"></a>Part 3: 扩展定律（Scaling Laws）</h3><p><strong>目标：</strong> 在小规模做实验，预测大规模的超参数&#x2F;损失</p>
<p><strong>问题：</strong> 给定 FLOPs 预算 C，使用更大的模型 N 还是训练更多 token D？</p>
<p><strong>计算最优扩展定律：</strong> Kaplan et al. (2020), Chinchilla</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/chinchilla-isoflop.png" srcset="/img/loading.gif" lazyload alt="Chinchilla Isoflop"></p>
<p><strong>结论：</strong> D* &#x3D; 20 N*（例如，1.4B 参数模型应在 28B token 上训练）</p>
<p><strong>注意：</strong> 这没有考虑推理成本！</p>
<h4 id="Assignment-3"><a href="#Assignment-3" class="headerlink" title="Assignment 3"></a>Assignment 3</h4><p><strong>GitHub（2024）：</strong> <a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/spring2024-assignment3-scaling">https://github.com/stanford-cs336/spring2024-assignment3-scaling</a></p>
<p><strong>任务：</strong></p>
<ul>
<li>我们定义训练 API（超参数 → 损失）基于之前的运行</li>
<li>提交”训练作业”（在 FLOPs 预算下）并收集数据点</li>
<li>拟合扩展定律到数据点</li>
<li>提交扩展后超参数的预测</li>
<li>排行榜：在 FLOPs 预算下最小化损失</li>
</ul>
<hr>
<h3 id="Part-4-数据（Data）"><a href="#Part-4-数据（Data）" class="headerlink" title="Part 4: 数据（Data）"></a>Part 4: 数据（Data）</h3><p><strong>问题：</strong> 我们希望模型具有什么能力？</p>
<p>多语言？代码？数学？</p>
<p><img src="https://ar5iv.labs.arxiv.org/html/2101.00027/assets/pile_chart2.png" srcset="/img/loading.gif" lazyload alt="The Pile Chart"></p>
<h4 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h4><ul>
<li><strong>困惑度：</strong> 语言模型的教科书评估</li>
<li><strong>标准化测试：</strong> MMLU, HellaSwag, GSM8K</li>
<li><strong>指令遵循：</strong> AlpacaEval, IFEval, WildBench</li>
<li><strong>扩展测试时计算：</strong> Chain-of-thought, 集成</li>
<li><strong>LM-as-a-judge：</strong> 评估生成任务</li>
<li><strong>完整系统：</strong> RAG, agents</li>
</ul>
<h4 id="数据策划"><a href="#数据策划" class="headerlink" title="数据策划"></a>数据策划</h4><ul>
<li>数据不会从天而降</li>
<li><strong>来源：</strong> 从互联网爬取的网页、书籍、arXiv 论文、GitHub 代码等</li>
<li><strong>版权：</strong> 诉诸合理使用来训练版权数据？</li>
<li><strong>许可：</strong> 可能需要许可数据（如 Google 与 Reddit）</li>
<li><strong>格式：</strong> HTML, PDF, 目录（不是文本！）</li>
</ul>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><ul>
<li><strong>转换：</strong> 将 HTML&#x2F;PDF 转换为文本（保留内容、一些结构、重写）</li>
<li><strong>过滤：</strong> 保留高质量数据，删除有害内容（通过分类器）</li>
<li><strong>去重：</strong> 节省计算，避免记忆；使用 Bloom 过滤器或 MinHash</li>
</ul>
<h4 id="Assignment-4"><a href="#Assignment-4" class="headerlink" title="Assignment 4"></a>Assignment 4</h4><p><strong>GitHub（2024）：</strong> <a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/spring2024-assignment4-data">https://github.com/stanford-cs336/spring2024-assignment4-data</a></p>
<p><strong>任务：</strong></p>
<ul>
<li>将 Common Crawl HTML 转换为文本</li>
<li>训练分类器过滤质量和有害内容</li>
<li>使用 MinHash 去重</li>
<li>排行榜：在 token 预算下最小化困惑度</li>
</ul>
<hr>
<h3 id="Part-5-对齐（Alignment）"><a href="#Part-5-对齐（Alignment）" class="headerlink" title="Part 5: 对齐（Alignment）"></a>Part 5: 对齐（Alignment）</h3><p><strong>基础模型：</strong> 原始潜力，非常擅长完成下一个 token</p>
<p><strong>对齐：</strong> 使模型真正有用</p>
<p><strong>对齐目标：</strong></p>
<ul>
<li>让语言模型遵循指令</li>
<li>调整风格（格式、长度、语气等）</li>
<li>纳入安全性（如拒绝回答有害问题）</li>
</ul>
<h4 id="监督微调（SFT）"><a href="#监督微调（SFT）" class="headerlink" title="监督微调（SFT）"></a>监督微调（SFT）</h4><p><strong>指令数据：</strong> (prompt, response) 对</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">ChatExample(<br>    turns=[<br>        Turn(role=<span class="hljs-string">&quot;system&quot;</span>, content=<span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>),<br>        Turn(role=<span class="hljs-string">&quot;user&quot;</span>, content=<span class="hljs-string">&quot;What is 1 + 1?&quot;</span>),<br>        Turn(role=<span class="hljs-string">&quot;assistant&quot;</span>, content=<span class="hljs-string">&quot;The answer is 2.&quot;</span>),<br>    ],<br>)<br></code></pre></td></tr></table></figure>

<p><strong>数据：</strong> 通常涉及人工标注</p>
<p><strong>直觉：</strong> 基础模型已经有技能，只需要少量示例来激发它们</p>
<p><strong>方法：</strong> 监督学习，微调模型以最大化 p(response | prompt)</p>
<h4 id="从反馈中学习"><a href="#从反馈中学习" class="headerlink" title="从反馈中学习"></a>从反馈中学习</h4><p><strong>偏好数据：</strong> 使用模型生成多个响应（如 [A, B]）到给定提示</p>
<p>用户提供偏好（如 A &lt; B 或 A &gt; B）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">PreferenceExample(<br>    history=[<br>        Turn(role=<span class="hljs-string">&quot;system&quot;</span>, content=<span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>),<br>        Turn(role=<span class="hljs-string">&quot;user&quot;</span>, content=<span class="hljs-string">&quot;What is the best way to train a language model?&quot;</span>),<br>    ],<br>    response_a=<span class="hljs-string">&quot;You should use a large dataset and train for a long time.&quot;</span>,<br>    response_b=<span class="hljs-string">&quot;You should use a small dataset and train for a short time.&quot;</span>,<br>    chosen=<span class="hljs-string">&quot;a&quot;</span>,<br>)<br></code></pre></td></tr></table></figure>

<p><strong>验证器：</strong></p>
<ul>
<li>形式验证器（如代码、数学）</li>
<li>学习验证器：针对 LM-as-a-judge 训练</li>
</ul>
<p><strong>算法：</strong></p>
<ul>
<li><strong>PPO：</strong> 来自强化学习的近端策略优化</li>
<li><strong>DPO：</strong> 直接策略优化，用于偏好数据，更简单</li>
<li><strong>GRPO：</strong> 组相对偏好优化，移除价值函数</li>
</ul>
<h4 id="Assignment-5"><a href="#Assignment-5" class="headerlink" title="Assignment 5"></a>Assignment 5</h4><p><strong>GitHub（2024）：</strong> <a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/spring2024-assignment5-alignment">https://github.com/stanford-cs336/spring2024-assignment5-alignment</a></p>
<p><strong>任务：</strong></p>
<ul>
<li>实现监督微调</li>
<li>实现直接偏好优化（DPO）</li>
<li>实现组相对偏好优化（GRPO）</li>
</ul>
<hr>
<h2 id="效率驱动设计决策"><a href="#效率驱动设计决策" class="headerlink" title="效率驱动设计决策"></a>效率驱动设计决策</h2><p><strong>当前：</strong> 我们受计算约束，因此设计决策将反映充分利用给定硬件</p>
<ul>
<li><strong>数据处理：</strong> 避免在坏&#x2F;无关数据上浪费宝贵计算</li>
<li><strong>Tokenization：</strong> 使用原始字节很优雅，但在当今模型架构下计算效率低</li>
<li><strong>模型架构：</strong> 许多变化是为了减少内存或 FLOPs（如共享 KV 缓存、滑动窗口注意力）</li>
<li><strong>训练：</strong> 我们可以只用一个 epoch！</li>
<li><strong>扩展定律：</strong> 在较小模型上使用更少计算进行超参数调优</li>
<li><strong>对齐：</strong> 如果将模型更多调整到期望用例，需要更小的基础模型</li>
</ul>
<p><strong>未来：</strong> 我们将变得数据受限…</p>
<hr>
<h2 id="Tokenization-详解"><a href="#Tokenization-详解" class="headerlink" title="Tokenization 详解"></a>Tokenization 详解</h2><blockquote>
<p>本单元受 Andrej Karpathy 关于 tokenization 的视频启发，推荐观看！<br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=zduSFxRajkE">YouTube 视频</a></p>
</blockquote>
<hr>
<h3 id="什么是-Tokenization？"><a href="#什么是-Tokenization？" class="headerlink" title="什么是 Tokenization？"></a>什么是 Tokenization？</h3><p><strong>原始文本：</strong> 通常表示为 Unicode 字符串</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">string = <span class="hljs-string">&quot;Hello, 🌍! 你好!&quot;</span><br></code></pre></td></tr></table></figure>

<p><strong>语言模型：</strong> 在 token 序列（通常用整数索引表示）上放置概率分布</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">indices = [<span class="hljs-number">15496</span>, <span class="hljs-number">11</span>, <span class="hljs-number">995</span>, <span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<p><strong>需求：</strong></p>
<ul>
<li><strong>编码（Encode）：</strong> 将字符串转换为 token 的过程</li>
<li><strong>解码（Decode）：</strong> 将 token 转换回字符串的过程</li>
</ul>
<p><strong>Tokenizer：</strong> 实现 encode 和 decode 方法的类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tokenizer</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br></code></pre></td></tr></table></figure>

<p><strong>词汇表大小（Vocabulary Size）：</strong> 可能的 token 数量（整数）</p>
<hr>
<h3 id="Tokenization-示例"><a href="#Tokenization-示例" class="headerlink" title="Tokenization 示例"></a>Tokenization 示例</h3><p><strong>交互式网站：</strong> <a target="_blank" rel="noopener" href="https://tiktokenizer.vercel.app/?encoder=gpt2">https://tiktokenizer.vercel.app/?encoder=gpt2</a></p>
<p><strong>观察：</strong></p>
<ul>
<li>单词及其前面的空格是同一个 token 的一部分（如 “ world”）</li>
<li>开头和中间的单词表示不同（如 “hello hello”）</li>
<li>数字被 tokenize 为每几位数字</li>
</ul>
<p><strong>GPT-2 Tokenizer 实战：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = tiktoken.get_encoding(<span class="hljs-string">&quot;gpt2&quot;</span>)<br>string = <span class="hljs-string">&quot;Hello, 🌍! 你好!&quot;</span><br><br><span class="hljs-comment"># 编码</span><br>indices = tokenizer.encode(string)<br><span class="hljs-comment"># 输出: [15496, 11, 12520, 234, 171, 120, 234, 0, 220, 20998, 25001, 171, 120, 234]</span><br><br><span class="hljs-comment"># 解码</span><br>reconstructed_string = tokenizer.decode(indices)<br><span class="hljs-comment"># 输出: &quot;Hello, 🌍! 你好!&quot;</span><br><br><span class="hljs-keyword">assert</span> string == reconstructed_string  <span class="hljs-comment"># 往返一致性</span><br><br><span class="hljs-comment"># 压缩率</span><br>compression_ratio = <span class="hljs-built_in">len</span>(string.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)) / <span class="hljs-built_in">len</span>(indices)<br><span class="hljs-comment"># 约 1.5-2.0</span><br></code></pre></td></tr></table></figure>

<hr>
<h3 id="方法-1-基于字符的-Tokenization"><a href="#方法-1-基于字符的-Tokenization" class="headerlink" title="方法 1: 基于字符的 Tokenization"></a>方法 1: 基于字符的 Tokenization</h3><p><strong>原理：</strong> Unicode 字符串是 Unicode 字符的序列</p>
<p><strong>转换：</strong></p>
<ul>
<li>字符 → 码点（整数）：<code>ord()</code></li>
<li>码点 → 字符：<code>chr()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">assert</span> <span class="hljs-built_in">ord</span>(<span class="hljs-string">&quot;a&quot;</span>) == <span class="hljs-number">97</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">ord</span>(<span class="hljs-string">&quot;🌍&quot;</span>) == <span class="hljs-number">127757</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">chr</span>(<span class="hljs-number">97</span>) == <span class="hljs-string">&quot;a&quot;</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">chr</span>(<span class="hljs-number">127757</span>) == <span class="hljs-string">&quot;🌍&quot;</span><br></code></pre></td></tr></table></figure>

<p><strong>实现：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CharacterTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">ord</span>, string))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>.join(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">chr</span>, indices))<br></code></pre></td></tr></table></figure>

<p><strong>测试：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = CharacterTokenizer()<br>string = <span class="hljs-string">&quot;Hello, 🌍! 你好!&quot;</span><br>indices = tokenizer.encode(string)<br><span class="hljs-comment"># [72, 101, 108, 108, 111, 44, 32, 127757, 33, 32, 20320, 22909, 33]</span><br><br>reconstructed_string = tokenizer.decode(indices)<br><span class="hljs-keyword">assert</span> string == reconstructed_string<br></code></pre></td></tr></table></figure>

<p><strong>问题：</strong></p>
<ol>
<li><strong>词汇表太大：</strong> 约 150K Unicode 字符</li>
<li><strong>效率低：</strong> 许多字符非常罕见（如 🌍），词汇表使用效率低</li>
<li><strong>压缩率差：</strong> compression_ratio ≈ 1.0</li>
</ol>
<hr>
<h3 id="方法-2-基于字节的-Tokenization"><a href="#方法-2-基于字节的-Tokenization" class="headerlink" title="方法 2: 基于字节的 Tokenization"></a>方法 2: 基于字节的 Tokenization</h3><p><strong>原理：</strong> Unicode 字符串可以表示为字节序列</p>
<p><strong>UTF-8 编码：</strong> 最常见的 Unicode 编码</p>
<ul>
<li>某些字符用 1 个字节表示：<code>&quot;a&quot;</code> → <code>b&quot;a&quot;</code></li>
<li>其他字符需要多个字节：<code>&quot;🌍&quot;</code> → <code>b&quot;\xf0\x9f\x8c\x8d&quot;</code></li>
</ul>
<p><strong>实现：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ByteTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        string_bytes = string.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)<br>        indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, string_bytes))<br>        <span class="hljs-keyword">return</span> indices<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        string_bytes = <span class="hljs-built_in">bytes</span>(indices)<br>        string = string_bytes.decode(<span class="hljs-string">&quot;utf-8&quot;</span>)<br>        <span class="hljs-keyword">return</span> string<br></code></pre></td></tr></table></figure>

<p><strong>测试：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = ByteTokenizer()<br>string = <span class="hljs-string">&quot;Hello, 🌍! 你好!&quot;</span><br>indices = tokenizer.encode(string)<br><span class="hljs-comment"># [72, 101, 108, 108, 111, 44, 32, 240, 159, 140, 141, 33, 32, 228, 189, 160, 229, 165, 189, 33]</span><br><br>reconstructed_string = tokenizer.decode(indices)<br><span class="hljs-keyword">assert</span> string == reconstructed_string<br></code></pre></td></tr></table></figure>

<p><strong>优点：</strong></p>
<ul>
<li>✅ 词汇表小：256（一个字节可以表示 256 个值）</li>
</ul>
<p><strong>问题：</strong></p>
<ul>
<li>❌ 压缩率糟糕：compression_ratio &#x3D; 1.0</li>
<li>❌ 序列太长</li>
<li>❌ 由于 Transformer 的上下文长度有限（注意力是二次的），这不太好…</li>
</ul>
<hr>
<h3 id="方法-3-基于单词的-Tokenization"><a href="#方法-3-基于单词的-Tokenization" class="headerlink" title="方法 3: 基于单词的 Tokenization"></a>方法 3: 基于单词的 Tokenization</h3><p><strong>原理：</strong> 将字符串分割成单词（经典 NLP 方法）</p>
<p><strong>简单正则表达式：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">string = <span class="hljs-string">&quot;I&#x27;ll say supercalifragilisticexpialidocious!&quot;</span><br>segments = regex.findall(<span class="hljs-string">r&quot;\w+|.&quot;</span>, string)<br><span class="hljs-comment"># [&#x27;I&#x27;, &#x27;ll&#x27;, &#x27;say&#x27;, &#x27;supercalifragilisticexpialidocious&#x27;, &#x27;!&#x27;]</span><br></code></pre></td></tr></table></figure>

<p><strong>GPT-2 风格正则表达式：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">GPT2_TOKENIZER_REGEX = <span class="hljs-string">r&quot;&quot;&quot;&#x27;(?:[sdmt]|ll|ve|re)| ?\p&#123;L&#125;+| ?\p&#123;N&#125;+| ?[^\s\p&#123;L&#125;\p&#123;N&#125;]+|\s+(?!\S)|\s+&quot;&quot;&quot;</span><br><br>segments = regex.findall(GPT2_TOKENIZER_REGEX, string)<br><span class="hljs-comment"># [&#x27;I&#x27;, &quot;&#x27;ll&quot;, &#x27; say&#x27;, &#x27; supercalifragilisticexpialidocious&#x27;, &#x27;!&#x27;]</span><br></code></pre></td></tr></table></figure>

<p><strong>问题：</strong></p>
<ol>
<li><strong>单词数量巨大：</strong> 类似 Unicode 字符</li>
<li><strong>许多单词罕见：</strong> 模型学不到太多</li>
<li><strong>没有固定词汇表大小</strong></li>
<li><strong>未见过的单词：</strong> 需要特殊的 UNK token，影响困惑度计算</li>
</ol>
<hr>
<h3 id="方法-4-Byte-Pair-Encoding-BPE"><a href="#方法-4-Byte-Pair-Encoding-BPE" class="headerlink" title="方法 4: Byte Pair Encoding (BPE)"></a>方法 4: Byte Pair Encoding (BPE)</h3><p><strong>历史：</strong></p>
<ul>
<li>1994 年由 Philip Gage 引入用于数据压缩</li>
<li>2016 年适配到 NLP 用于神经机器翻译（Sennrich et al.）</li>
<li>GPT-2 使用 BPE</li>
</ul>
<p><strong>基本思想：</strong> 在原始文本上<strong>训练</strong> tokenizer 以自动确定词汇表</p>
<p><strong>直觉：</strong> 常见字符序列用单个 token 表示，罕见序列用多个 token 表示</p>
<p><strong>算法草图：</strong> 从每个字节作为 token 开始，逐步合并最常见的相邻 token 对</p>
<hr>
<h4 id="BPE-训练过程"><a href="#BPE-训练过程" class="headerlink" title="BPE 训练过程"></a>BPE 训练过程</h4><p><strong>示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">string = <span class="hljs-string">&quot;the cat in the hat&quot;</span><br>num_merges = <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure>

<p><strong>步骤 1：</strong> 从字节开始</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">indices = [<span class="hljs-number">116</span>, <span class="hljs-number">104</span>, <span class="hljs-number">101</span>, <span class="hljs-number">32</span>, <span class="hljs-number">99</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>, <span class="hljs-number">32</span>, <span class="hljs-number">105</span>, <span class="hljs-number">110</span>, <span class="hljs-number">32</span>, <span class="hljs-number">116</span>, <span class="hljs-number">104</span>, <span class="hljs-number">101</span>, <span class="hljs-number">32</span>, <span class="hljs-number">104</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>]<br><span class="hljs-comment"># 对应: t h e   c a t   i n   t h e   h a t</span><br></code></pre></td></tr></table></figure>

<p><strong>步骤 2：</strong> 统计相邻 token 对的出现次数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">counts = &#123;<br>    (<span class="hljs-number">116</span>, <span class="hljs-number">104</span>): <span class="hljs-number">2</span>,  <span class="hljs-comment"># &quot;th&quot;</span><br>    (<span class="hljs-number">104</span>, <span class="hljs-number">101</span>): <span class="hljs-number">2</span>,  <span class="hljs-comment"># &quot;he&quot;</span><br>    (<span class="hljs-number">101</span>, <span class="hljs-number">32</span>): <span class="hljs-number">2</span>,   <span class="hljs-comment"># &quot;e &quot;</span><br>    (<span class="hljs-number">32</span>, <span class="hljs-number">116</span>): <span class="hljs-number">1</span>,   <span class="hljs-comment"># &quot; t&quot;</span><br>    ...<br>&#125;<br></code></pre></td></tr></table></figure>

<p><strong>步骤 3：</strong> 找到最常见的对并合并</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第一次合并: (116, 104) -&gt; 256  # &quot;th&quot;</span><br>indices = [<span class="hljs-number">256</span>, <span class="hljs-number">101</span>, <span class="hljs-number">32</span>, <span class="hljs-number">99</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>, <span class="hljs-number">32</span>, <span class="hljs-number">105</span>, <span class="hljs-number">110</span>, <span class="hljs-number">32</span>, <span class="hljs-number">256</span>, <span class="hljs-number">101</span>, <span class="hljs-number">32</span>, <span class="hljs-number">104</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>]<br><br><span class="hljs-comment"># 第二次合并: (256, 101) -&gt; 257  # &quot;the&quot;</span><br>indices = [<span class="hljs-number">257</span>, <span class="hljs-number">32</span>, <span class="hljs-number">99</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>, <span class="hljs-number">32</span>, <span class="hljs-number">105</span>, <span class="hljs-number">110</span>, <span class="hljs-number">32</span>, <span class="hljs-number">257</span>, <span class="hljs-number">32</span>, <span class="hljs-number">104</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>]<br><br><span class="hljs-comment"># 第三次合并: (257, 32) -&gt; 258  # &quot;the &quot;</span><br>indices = [<span class="hljs-number">258</span>, <span class="hljs-number">99</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>, <span class="hljs-number">32</span>, <span class="hljs-number">105</span>, <span class="hljs-number">110</span>, <span class="hljs-number">32</span>, <span class="hljs-number">258</span>, <span class="hljs-number">104</span>, <span class="hljs-number">97</span>, <span class="hljs-number">116</span>]<br></code></pre></td></tr></table></figure>

<p><strong>结果：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">vocab = &#123;<br>    <span class="hljs-number">0</span>-<span class="hljs-number">255</span>: 原始字节,<br>    <span class="hljs-number">256</span>: <span class="hljs-string">b&quot;th&quot;</span>,<br>    <span class="hljs-number">257</span>: <span class="hljs-string">b&quot;the&quot;</span>,<br>    <span class="hljs-number">258</span>: <span class="hljs-string">b&quot;the &quot;</span>,<br>&#125;<br><br>merges = &#123;<br>    (<span class="hljs-number">116</span>, <span class="hljs-number">104</span>): <span class="hljs-number">256</span>,<br>    (<span class="hljs-number">256</span>, <span class="hljs-number">101</span>): <span class="hljs-number">257</span>,<br>    (<span class="hljs-number">257</span>, <span class="hljs-number">32</span>): <span class="hljs-number">258</span>,<br>&#125;<br></code></pre></td></tr></table></figure>

<hr>
<h4 id="BPE-实现"><a href="#BPE-实现" class="headerlink" title="BPE 实现"></a>BPE 实现</h4><p><strong>数据结构：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">frozen=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BPETokenizerParams</span>:<br>    vocab: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">bytes</span>]              <span class="hljs-comment"># index -&gt; bytes</span><br>    merges: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>], <span class="hljs-built_in">int</span>]   <span class="hljs-comment"># (index1, index2) -&gt; new_index</span><br></code></pre></td></tr></table></figure>

<p><strong>训练函数：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_bpe</span>(<span class="hljs-params">string: <span class="hljs-built_in">str</span>, num_merges: <span class="hljs-built_in">int</span></span>) -&gt; BPETokenizerParams:<br>    <span class="hljs-comment"># 从字节开始</span><br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, string.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)))<br>    merges = &#123;&#125;<br>    vocab = &#123;x: <span class="hljs-built_in">bytes</span>([x]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125;<br>    <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_merges):<br>        <span class="hljs-comment"># 统计相邻对</span><br>        counts = defaultdict(<span class="hljs-built_in">int</span>)<br>        <span class="hljs-keyword">for</span> index1, index2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(indices, indices[<span class="hljs-number">1</span>:]):<br>            counts[(index1, index2)] += <span class="hljs-number">1</span><br>        <br>        <span class="hljs-comment"># 找到最常见的对</span><br>        pair = <span class="hljs-built_in">max</span>(counts, key=counts.get)<br>        index1, index2 = pair<br>        <br>        <span class="hljs-comment"># 合并</span><br>        new_index = <span class="hljs-number">256</span> + i<br>        merges[pair] = new_index<br>        vocab[new_index] = vocab[index1] + vocab[index2]<br>        indices = merge(indices, pair, new_index)<br>    <br>    <span class="hljs-keyword">return</span> BPETokenizerParams(vocab=vocab, merges=merges)<br></code></pre></td></tr></table></figure>

<p><strong>合并辅助函数：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">merge</span>(<span class="hljs-params">indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>], pair: <span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>], new_index: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>    <span class="hljs-string">&quot;&quot;&quot;将 indices 中所有 pair 的实例替换为 new_index&quot;&quot;&quot;</span><br>    new_indices = []<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i &lt; <span class="hljs-built_in">len</span>(indices):<br>        <span class="hljs-keyword">if</span> i + <span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(indices) <span class="hljs-keyword">and</span> indices[i] == pair[<span class="hljs-number">0</span>] <span class="hljs-keyword">and</span> indices[i + <span class="hljs-number">1</span>] == pair[<span class="hljs-number">1</span>]:<br>            new_indices.append(new_index)<br>            i += <span class="hljs-number">2</span><br>        <span class="hljs-keyword">else</span>:<br>            new_indices.append(indices[i])<br>            i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> new_indices<br></code></pre></td></tr></table></figure>

<p><strong>Tokenizer 类：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BPETokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, params: BPETokenizerParams</span>):<br>        self.params = params<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, string.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)))<br>        <span class="hljs-comment"># 注意：这是一个非常慢的实现</span><br>        <span class="hljs-keyword">for</span> pair, new_index <span class="hljs-keyword">in</span> self.params.merges.items():<br>            indices = merge(indices, pair, new_index)<br>        <span class="hljs-keyword">return</span> indices<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        bytes_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(self.params.vocab.get, indices))<br>        string = <span class="hljs-string">b&quot;&quot;</span>.join(bytes_list).decode(<span class="hljs-string">&quot;utf-8&quot;</span>)<br>        <span class="hljs-keyword">return</span> string<br></code></pre></td></tr></table></figure>

<hr>
<h4 id="使用-BPE-Tokenizer"><a href="#使用-BPE-Tokenizer" class="headerlink" title="使用 BPE Tokenizer"></a>使用 BPE Tokenizer</h4><p><strong>训练：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">string = <span class="hljs-string">&quot;the cat in the hat&quot;</span><br>params = train_bpe(string, num_merges=<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure>

<p><strong>编码新文本：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = BPETokenizer(params)<br>string = <span class="hljs-string">&quot;the quick brown fox&quot;</span><br>indices = tokenizer.encode(string)<br>reconstructed_string = tokenizer.decode(indices)<br><span class="hljs-keyword">assert</span> string == reconstructed_string<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="Assignment-1-中的改进"><a href="#Assignment-1-中的改进" class="headerlink" title="Assignment 1 中的改进"></a>Assignment 1 中的改进</h3><p>在 Assignment 1 中，你需要超越这个基础实现：</p>
<ol>
<li><strong>优化 encode()：</strong> 当前循环所有合并，只循环相关的合并</li>
<li><strong>特殊 token：</strong> 检测并保留特殊 token（如 <code>&lt;|endoftext|&gt;</code>）</li>
<li><strong>预 tokenization：</strong> 使用 GPT-2 tokenizer 正则表达式</li>
<li><strong>性能优化：</strong> 尽可能提高实现速度</li>
</ol>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="Tokenization-要点"><a href="#Tokenization-要点" class="headerlink" title="Tokenization 要点"></a>Tokenization 要点</h3><ul>
<li><strong>Tokenizer：</strong> 字符串 ↔ token（索引）</li>
<li><strong>基于字符、字节、单词的 tokenization：</strong> 高度次优</li>
<li><strong>BPE：</strong> 查看语料库统计的有效启发式方法</li>
<li><strong>Tokenization 是必要之恶：</strong> 也许有一天我们会直接从字节做起…</li>
</ul>
<h3 id="下节课预告"><a href="#下节课预告" class="headerlink" title="下节课预告"></a>下节课预告</h3><p><strong>主题：</strong> PyTorch 构建块，资源核算</p>
<hr>
<h2 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h2><p><strong>Tokenization：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=zduSFxRajkE">Andrej Karpathy’s Tokenization Video</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Byte_pair_encoding">BPE Wikipedia</a></li>
<li><a target="_blank" rel="noopener" href="http://www.pennelynn.com/Documents/CUJ/HTML/94HTML/19940045.HTM">Original BPE Paper (Gage 1994)</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1508.07909">BPE for NMT (Sennrich et al. 2016)</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/openai/tiktoken">tiktoken (OpenAI)</a></li>
</ul>
<p><strong>课程资源：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://stanford-cs336.github.io/spring2025/">Course Website</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/assignment1-basics">Assignment 1 GitHub</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/spring2024-assignment1-basics-leaderboard">2024 Leaderboard</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/linux/" class="category-chain-item">linux</a>
  
  
    <span>></span>
    
  <a href="/categories/linux/drivers/" class="category-chain-item">drivers</a>
  
  
    <span>></span>
    
  <a href="/categories/linux/drivers/gpu/" class="category-chain-item">gpu</a>
  
  
    <span>></span>
    
  <a href="/categories/linux/drivers/gpu/stanford-cs336/" class="category-chain-item">stanford-cs336</a>
  
  

  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/architect/">#architect</a>
      
        <a href="/tags/git/">#git</a>
      
        <a href="/tags/go/">#go</a>
      
        <a href="/tags/gpu/">#gpu</a>
      
        <a href="/tags/kernel/">#kernel</a>
      
        <a href="/tags/log/">#log</a>
      
        <a href="/tags/perf/">#perf</a>
      
        <a href="/tags/python/">#python</a>
      
        <a href="/tags/sources/">#sources</a>
      
        <a href="/tags/net/">#net</a>
      
        <a href="/tags/struct/">#struct</a>
      
        <a href="/tags/mm/">#mm</a>
      
        <a href="/tags/stanford-cs336/">#stanford-cs336</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>大模型从0到1｜第一讲：概述和Tokenization</div>
      <div>https://realwujing.github.io/linux/drivers/gpu/stanford-cs336/大模型从0到1｜第一讲：概述和tokenization/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Wu Jing</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年11月22日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/linux/drivers/gpu/stanford-cs336/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8E0%E5%88%B01%EF%BD%9C%E7%AC%AC%E4%BA%8C%E8%AE%B2%EF%BC%9Apytorch%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BALLM/" title="大模型从0到1｜第二讲：PyTorch手把手搭建LLM">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">大模型从0到1｜第二讲：PyTorch手把手搭建LLM</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/linux/drivers/%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/" title="设备驱动">
                        <span class="hidden-mobile">设备驱动</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"c11f8471a6ae4d3eea12","clientSecret":"87bfa232882af2b005f4c3352132dd418bf6d113","repo":"realwujing.github.io","owner":"realwujing","admin":["realwujing"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":false,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},
          {
            id: '0eb7c58142e7784f514b389194a075cd'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.events.registerRefreshCallback(function() {
      if ('mermaid' in window) {
        mermaid.init();
      }
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
