

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicon.jpg">
  <link rel="icon" href="/images/favicon.jpg">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Wu Jing">
  <meta name="keywords" content="HTML, JavaScript, Hexo, Linux, qemu, C++, namespace, git, bcc, bpf, initramfs, k8s, architect, strings, assembly, linux">
  
    <meta name="description" content="grub中iommu&#x3D;pt的作用 linux iommu的作用？grub中iommu&#x3D;pt的作用？ 在Linux系统中，IOMMU（Input-Output Memory Management Unit）和相关的内核参数（如iommu&#x3D;pt）主要用于管理设备对内存的访问，以下是详细解释：  1. Linux中IOMMU的作用 IOMMU是一种硬件特性（如Intel的VT-d或AMD的VI），其核心">
<meta property="og:type" content="article">
<meta property="og:title" content="grub中iommu&#x3D;pt的作用">
<meta property="og:url" content="https://realwujing.github.io/linux/debug/grub/grub%E4%B8%ADiommu=pt%E7%9A%84%E4%BD%9C%E7%94%A8/index.html">
<meta property="og:site_name" content="WuJing&#39;s Blog">
<meta property="og:description" content="grub中iommu&#x3D;pt的作用 linux iommu的作用？grub中iommu&#x3D;pt的作用？ 在Linux系统中，IOMMU（Input-Output Memory Management Unit）和相关的内核参数（如iommu&#x3D;pt）主要用于管理设备对内存的访问，以下是详细解释：  1. Linux中IOMMU的作用 IOMMU是一种硬件特性（如Intel的VT-d或AMD的VI），其核心">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-04-18T10:49:13.000Z">
<meta property="article:modified_time" content="2025-04-18T10:49:13.000Z">
<meta property="article:author" content="Wu Jing">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="qemu">
<meta property="article:tag" content="linux">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>grub中iommu=pt的作用 - WuJing&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"realwujing.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"6b5123e146041483d13bdfaeb6e42a76","google":"UA-265632133-1","tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null},"gtag":"G-E7BV6T4RCW","woyaola":null,"cnzz":null},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?6b5123e146041483d13bdfaeb6e42a76";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>WuJing&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="grub中iommu=pt的作用"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-04-18 10:49" pubdate>
          2025年4月18日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          74 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">grub中iommu=pt的作用</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="grub中iommupt的作用">grub中iommu=pt的作用</h1>
<h2 id="linux-iommu的作用grub中iommupt的作用">linux
iommu的作用？grub中iommu=pt的作用？</h2>
<p>在Linux系统中，IOMMU（Input-Output Memory Management
Unit）和相关的内核参数（如<code>iommu=pt</code>）主要用于管理设备对内存的访问，以下是详细解释：</p>
<hr />
<h3 id="linux中iommu的作用"><strong>1. Linux中IOMMU的作用</strong></h3>
<p>IOMMU是一种硬件特性（如Intel的VT-d或AMD的VI），其核心功能包括： •
<strong>内存隔离与保护</strong>：防止设备直接访问任意物理内存，仅允许访问内核明确分配的地址空间，提升安全性（如防止DMA攻击）。
•
<strong>地址转换</strong>：将设备使用的虚拟地址（IOVA）转换为物理地址，支持大内存和非连续内存分配。
•
<strong>设备直通（Passthrough）</strong>：在虚拟化环境中，允许虚拟机直接控制物理设备（如GPU、网卡），IOMMU确保设备DMA操作仅限于虚拟机所属的内存区域。
• <strong>性能优化</strong>：减少内存拷贝（如通过<code>swiotlb</code>的
bounce buffer）。</p>
<hr />
<h3 id="iommupt的作用"><strong>2.
<code>iommu=pt</code>的作用</strong></h3>
<p>在GRUB内核启动参数中，<code>iommu=pt</code>（Pass-Through模式）的用途：
• <strong>仅对直通设备启用IOMMU</strong>：<br />
内核默认可能对所有设备启用IOMMU（如<code>iommu=on</code>），而<code>pt</code>模式仅对<strong>实际需要直通</strong>的设备（如分配给虚拟机的设备）启用IOMMU映射，其他设备绕过IOMMU，从而减少不必要的地址转换开销。
• <strong>性能优化</strong>：<br />
避免对普通设备（如内置网卡、磁盘控制器）的IOMMU管理开销，提升性能，尤其在不需要全系统IOMMU的场景下。</p>
<hr />
<h3 id="相关参数对比"><strong>3. 相关参数对比</strong></h3>
<table>
<thead>
<tr class="header">
<th>参数</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>iommu=on</code></td>
<td>强制启用所有设备的IOMMU（完全保护，可能有性能开销）</td>
</tr>
<tr class="even">
<td><code>iommu=off</code></td>
<td>完全禁用IOMMU（不安全，但无转换开销）</td>
</tr>
<tr class="odd">
<td><code>iommu=pt</code></td>
<td><strong>折中方案</strong>：仅直通设备使用IOMMU，其他设备直接访问内存</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="典型应用场景"><strong>4. 典型应用场景</strong></h3>
<p>• <strong>虚拟化（如KVM）</strong>：<br />
需直通设备给虚拟机时，<code>iommu=pt</code>确保直通设备隔离，同时避免非直通设备的性能损失。
• <strong>安全性要求高的场景</strong>：<br />
配合<code>iommu=strict</code>确保DMA严格受限，但可能牺牲性能。 •
<strong>调试</strong>：<br />
使用<code>iommu=debug</code>查看IOMMU初始化细节。</p>
<hr />
<h3 id="配置方法"><strong>5. 配置方法</strong></h3>
<p>在GRUB配置中（如<code>/etc/default/grub</code>）添加参数：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">GRUB_CMDLINE_LINUX=<span class="hljs-string">&quot;iommu=pt&quot;</span><br></code></pre></td></tr></table></figure>
<p>更新GRUB后重启：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo update-grub &amp;&amp; sudo reboot<br></code></pre></td></tr></table></figure>
<hr />
<h3 id="总结"><strong>总结</strong></h3>
<p>• <strong>IOMMU</strong>：提供设备内存访问的安全隔离和地址转换。 •
<strong><code>iommu=pt</code></strong>：优化性能，仅在必要时（如设备直通）启用IOMMU，适合虚拟化或特定设备隔离场景。</p>
<h2
id="给出流程图注明iommu在哪一层起作用">给出流程图，注明iommu在哪一层起作用？</h2>
<p>以下是IOMMU在Linux系统中的作用层次及流程图，结合硬件、内核和用户空间的交互关系：</p>
<hr />
<h3 id="iommu作用层次示意图"><strong>1.
IOMMU作用层次示意图</strong></h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">+-----------------------+<br>|     User Space         | ← 应用程序（如虚拟机、普通进程）<br>+-----------------------+<br>|     Kernel Space       | ← 驱动、内存管理、IOMMU子系统（iommu=pt参数生效处）<br>+-----------------------+<br>|     Hardware Layer     | ← IOMMU硬件（VT-d/AMD-Vi）、PCIe设备<br>+-----------------------+<br></code></pre></td></tr></table></figure>
<hr />
<h3 id="详细流程图"><strong>2. 详细流程图</strong></h3>
<pre><code class=" mermaid">flowchart TB
    A[系统启动] --&gt; B[BIOS/UEFI初始化]
    B --&gt; C&#123;是否启用IOMMU?&#125;
    C -- 是 --&gt; D[硬件IOMMU激活（VT-d/AMD-Vi）]
    C -- 否 --&gt; E[跳过IOMMU，直接DMA访问]
    D --&gt; F[GRUB加载内核参数]
    F --&gt; G&#123;检查iommu参数&#125;
    G -- iommu=pt --&gt; H[仅对直通设备启用IOMMU]
    G -- iommu=on --&gt; I[全局启用IOMMU]
    G -- iommu=off --&gt; E
    H --&gt; J[内核初始化时标记直通设备]
    I --&gt; K[所有设备通过IOMMU访问内存]
    J --&gt; L[设备DMA请求]
    L --&gt; M&#123;设备是否直通?&#125;
    M -- 是 --&gt; N[IOMMU转换地址（IOVA→PA）]
    M -- 否 --&gt; O[绕过IOMMU，直接访问物理内存]
    N --&gt; P[安全访问指定内存区域]
    O --&gt; Q[传统DMA操作（无隔离）]
</code></pre>
<hr />
<h3 id="关键点说明"><strong>3. 关键点说明</strong></h3>
<ol type="1">
<li><p><strong>硬件层</strong>：<br />
•
IOMMU是CPU/芯片组提供的硬件功能，位于PCIe设备和物理内存之间，负责地址转换和访问控制。</p></li>
<li><p><strong>内核层</strong>：<br />
•
<strong>GRUB参数</strong>（如<code>iommu=pt</code>）在内核启动时解析，决定IOMMU子系统的行为。<br />
•
内核的<strong>IOMMU子系统</strong>管理设备与内存的映射关系，直通设备（如VFIO绑定的设备）通过IOMMU隔离。</p></li>
<li><p><strong>用户层</strong>：<br />
•
虚拟机（如QEMU-KVM）通过VFIO驱动使用直通设备，依赖IOMMU保证安全。</p></li>
</ol>
<hr />
<h3 id="iommu的作用位置"><strong>4. IOMMU的作用位置</strong></h3>
<p>•
<strong>地址转换</strong>：在设备发起DMA时，IOMMU硬件将设备看到的<strong>IO虚拟地址（IOVA）</strong>转换为<strong>物理地址（PA）</strong>。<br />
• <strong>访问控制</strong>：IOMMU的<strong>DMAR（DMA
Remapping）表</strong>由内核配置，限制设备仅能访问授权内存。</p>
<hr />
<h3 id="典型场景示例"><strong>5. 典型场景示例</strong></h3>
<p>• <strong>虚拟化直通</strong>：</p>
<p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">虚拟机 → VFIO驱动 → 设备DMA → IOMMU转换 → 虚拟机专属内存<br></code></pre></td></tr></table></figure></p>
<p>• <strong>普通设备</strong>（<code>iommu=pt</code>时）：</p>
<p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">网卡驱动 → DMA请求 → 绕过IOMMU → 直接访问内核缓冲区<br></code></pre></td></tr></table></figure></p>
<hr />
<h3 id="总结-1"><strong>总结</strong></h3>
<p>•
<strong>流程图</strong>展示了从系统启动到设备DMA的完整路径，<code>iommu=pt</code>在内核初始化阶段介入，动态控制IOMMU的启用范围。<br />
•
<strong>核心作用层</strong>：IOMMU在<strong>硬件层执行转换</strong>，由<strong>内核层配置策略</strong>，最终保障用户层（如虚拟机）的内存安全。</p>
<h2
id="虚拟机-vfio驱动-设备dma-iommu转换-虚拟机专属内存-这里没有iommu会怎样">虚拟机
→ VFIO驱动 → 设备DMA → IOMMU转换 → 虚拟机专属内存
这里没有iommu会怎样？</h2>
<p>如果虚拟机直通设备（PCIe
Passthrough）时<strong>没有IOMMU</strong>，会导致严重的安全性和功能问题，具体表现如下：</p>
<hr />
<h3 id="安全问题dma攻击直接内存访问失控"><strong>1.
安全问题：DMA攻击（直接内存访问失控）</strong></h3>
<p>• <strong>设备可以访问任意物理内存</strong>：<br />
未隔离的DMA操作允许直通设备读写<strong>宿主机全部物理内存</strong>，包括：
• 其他虚拟机的内存。 • 宿主机内核敏感数据（如密码、密钥）。 •
其他进程的私有内存。 •
<strong>后果</strong>：恶意虚拟机可通过直通设备发起DMA攻击，篡改系统或窃取数据。</p>
<hr />
<h3 id="功能问题地址冲突与错误"><strong>2.
功能问题：地址冲突与错误</strong></h3>
<p>• <strong>物理地址错误</strong>：<br />
虚拟机内部的驱动认为设备DMA目标是虚拟机的“物理地址”（GPA），但设备实际直接使用宿主机的物理地址（HPA），两者不一致会导致：
• 数据写入错误的内存位置（如覆盖宿主关键数据）。 •
设备读取到无效数据，引发崩溃或静默错误。 • <strong>示例</strong>：<br />
虚拟机内网卡驱动配置DMA缓冲区地址为
<code>0x1000</code>（GPA），但宿主机中该地址可能对应完全不同的内容（如其他虚拟机内存）。</p>
<hr />
<h3 id="虚拟化场景的完全失效"><strong>3.
虚拟化场景的完全失效</strong></h3>
<p>• <strong>内存隔离破坏</strong>：<br />
虚拟化的核心要求是隔离各虚拟机的资源，无IOMMU时： •
直通设备可能读取其他虚拟机的磁盘数据（如通过NVMe SSD控制器）。 •
GPU直通可能泄露显存中的图形数据。 • <strong>稳定性问题</strong>：<br />
多虚拟机竞争同一设备的DMA资源会导致随机崩溃。</p>
<hr />
<h3 id="替代方案无iommu时的妥协方法"><strong>4.
替代方案（无IOMMU时的妥协方法）</strong></h3>
<p>若硬件不支持IOMMU，仍需要直通设备时，只能依赖以下<strong>不安全且低效</strong>的替代方案：</p>
<ol type="1">
<li><strong>软件模拟IOMMU（如QEMU的<code>-device ioh3420</code>）</strong>：<br />
通过软件拦截设备DMA并重定向地址，但性能极差（需陷入模拟层）。</li>
<li><strong>使用用户态驱动（如UIO）</strong>：<br />
将设备映射到用户空间，但无法解决DMA安全问题。</li>
<li><strong>禁用直通，改用虚拟设备（如virtio-net）</strong>：<br />
完全放弃性能，回归纯软件虚拟化。</li>
</ol>
<hr />
<h3 id="为什么iommu是必须的"><strong>5.
为什么IOMMU是必须的？</strong></h3>
<p>• <strong>硬件级隔离</strong>：<br />
IOMMU的地址转换表（由宿主机内核配置）确保设备DMA仅能访问<strong>指定虚拟机的内存区域</strong>。
• <strong>透明性</strong>：<br />
虚拟机无需感知宿主机物理地址，IOMMU自动完成<code>GPA→HPA</code>转换。 •
<strong>性能</strong>：<br />
硬件加速的地址转换（对比软件模拟可提升10倍以上吞吐量）。</p>
<hr />
<h3 id="总结-2"><strong>总结</strong></h3>
<p>无IOMMU的直通设备会：</p>
<ol type="1">
<li><strong>彻底破坏虚拟化隔离性</strong>，引发安全灾难。</li>
<li><strong>导致DMA操作混乱</strong>，使设备无法正常工作。</li>
<li><strong>迫使使用低效替代方案</strong>，丧失直通的性能优势。</li>
</ol>
<p>因此，在生产环境中，启用IOMMU（如<code>iommu=on</code>或<code>iommu=pt</code>）是PCIe
Passthrough的必要前提。</p>
<h2
id="虚拟机-vfio驱动-设备dma-iommu转换-虚拟机专属内存-这里进一步表明虚拟机专属内存与物理机专属内存的关系">虚拟机
→ VFIO驱动 → 设备DMA → IOMMU转换 → 虚拟机专属内存
这里进一步表明虚拟机专属内存与物理机专属内存的关系？</h2>
<p>在虚拟化环境中，<strong>虚拟机专属内存</strong>（Guest Physical
Memory, <strong>GPA</strong>）与<strong>物理机专属内存</strong>（Host
Physical Memory,
<strong>HPA</strong>）的关系由<strong>虚拟化层（KVM/QEMU）+
IOMMU</strong>共同管理，以下是详细解析：</p>
<hr />
<h3 id="内存映射关系"><strong>1. 内存映射关系</strong></h3>
<h4 id="虚拟机视角gpa">（1）<strong>虚拟机视角（GPA）</strong></h4>
<p>• 虚拟机（VM）认为自己独占连续的物理内存（GPA），例如： •
虚拟机内操作系统分配内存地址 <code>0x1000</code>（GPA）。 •
虚拟机驱动程序配置设备DMA目标为 <code>0x1000</code>（GPA）。</p>
<h4 id="物理机视角hpa">（2）<strong>物理机视角（HPA）</strong></h4>
<p>•
宿主机实际将虚拟机的GPA映射到<strong>分散的物理内存页</strong>（HPA），例如：
• GPA <code>0x1000</code> → HPA
<code>0x8000</code>（可能是宿主机的一个4KB页面）。 • GPA
<code>0x2000</code> → HPA <code>0x12000</code>（另一个物理页）。 •
这种映射由<strong>KVM内存虚拟化</strong>（EPT/NPT）维护，对虚拟机透明。</p>
<hr />
<h3 id="iommu的作用gpa-hpa的二次转换"><strong>2. IOMMU的作用：GPA →
HPA的二次转换</strong></h3>
<p>当直通设备发起DMA时，IOMMU需完成<strong>两级地址转换</strong>：</p>
<ol type="1">
<li><strong>虚拟机驱动 → GPA</strong><br />
设备DMA目标地址由虚拟机驱动设置为GPA（如 <code>0x1000</code>）。</li>
<li><strong>IOMMU转换：GPA → HPA</strong><br />
IOMMU通过<strong>I/O页表</strong>（由VFIO驱动配置）将GPA转换为真实的HPA（如
<code>0x8000</code>）。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">设备DMA请求:  [GPA 0x1000] → IOMMU转换 → [HPA 0x8000]<br></code></pre></td></tr></table></figure>
<h4 id="关键点"><strong>关键点</strong></h4>
<p>•
<strong>IOMMU的I/O页表</strong>由宿主机内核（VFIO驱动）动态维护，确保设备只能访问<strong>该虚拟机对应的HPA范围</strong>。
•
<strong>EPT/NPT</strong>（KVM的扩展页表）负责虚拟机内<code>GVA→GPA</code>的转换，而IOMMU负责<code>GPA→HPA</code>的转换，两者协作完成完整映射。</p>
<hr />
<h3 id="内存隔离示意图"><strong>3. 内存隔离示意图</strong></h3>
<pre><code class=" mermaid">flowchart LR
    subgraph 虚拟机1
        A[GPA 0x1000] --&gt;|DMA请求| B(IOMMU)
        C[GPA 0x2000] --&gt;|DMA请求| B
    end
    subgraph 宿主机物理内存
        B --&gt; D[HPA 0x8000]
        B --&gt; E[HPA 0x12000]
        F[HPA 0x30000] --&gt;|属于其他VM| G[虚拟机2内存]
    end
</code></pre>
<p>• <strong>隔离性</strong>：IOMMU确保虚拟机1的设备无法访问
<code>HPA 0x30000</code>（虚拟机2的内存）。</p>
<hr />
<h3 id="无iommu时的内存混乱"><strong>4.
无IOMMU时的内存混乱</strong></h3>
<p>若未启用IOMMU，设备直接使用GPA作为HPA，导致： •
<strong>地址错位</strong>：<br />
虚拟机内 <code>GPA 0x1000</code> 可能对应宿主机
<code>HPA 0x1000</code>（完全无关的数据）。 •
<strong>越界访问</strong>：<br />
设备可能写入宿主机的内核内存或其他虚拟机内存。</p>
<hr />
<h3 id="实际案例以kvm为例"><strong>5.
实际案例（以KVM为例）</strong></h3>
<ol type="1">
<li><p><strong>QEMU启动参数</strong>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">-device vfio-pci,host=01:00.0  <span class="hljs-comment"># 将物理设备01:00.0直通给虚拟机</span><br></code></pre></td></tr></table></figure></li>
<li><p><strong>内存分配流程</strong>：<br />
• 虚拟机分配
<code>GPA 0x1000</code>，QEMU通过<code>mmap</code>在宿主机分配
<code>HPA 0x8000</code>。<br />
• VFIO驱动将 <code>GPA 0x1000 → HPA 0x8000</code> 写入IOMMU页表。<br />
</p></li>
<li><p><strong>设备DMA</strong>：<br />
设备写入 <code>GPA 0x1000</code>，IOMMU自动重定向到
<code>HPA 0x8000</code>。</p></li>
</ol>
<hr />
<h3 id="总结-3"><strong>6. 总结</strong></h3>
<table>

<thead>
<tr class="header">
<th>概念</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>GPA</strong></td>
<td>虚拟机看到的“物理内存”，连续且独占（实际由宿主机碎片化映射）。</td>
</tr>
<tr class="even">
<td><strong>HPA</strong></td>
<td>宿主机真实的物理内存，可能被多个虚拟机共享（通过IOMMU隔离）。</td>
</tr>
<tr class="odd">
<td><strong>IOMMU转换</strong></td>
<td>将设备DMA的GPA动态转换为HPA，确保隔离性和正确性。</td>
</tr>
<tr class="even">
<td><strong>无IOMMU的后果</strong></td>
<td>DMA直接使用GPA作为HPA，导致内存污染、安全漏洞和系统崩溃。</td>
</tr>
</tbody>
</table>
<p>通过IOMMU的<code>GPA→HPA</code>转换，虚拟化环境实现了<strong>高性能的设备直通</strong>与<strong>严格的内存隔离</strong>。</p>
<h2
id="没有iommuept页表会将gpa转成hpa啊难道在vm-外设dma的时候ept扩展页表不参与">没有iommu，ept页表会将gpa转成hpa啊，难道在vm
外设dma的时候ept扩展页表不参与？</h2>
<p>你的问题非常关键！这里涉及到 <strong>EPT（Extended Page
Table，扩展页表）</strong> 和 <strong>IOMMU</strong>
在虚拟化环境中的分工协作关系。确实，EPT 负责将虚拟机内部的
<strong>GPA（Guest Physical Address）</strong> 转换为宿主机的
<strong>HPA（Host Physical Address）</strong>，但 <strong>EPT
并不直接参与外设 DMA 的地址转换</strong>，原因如下：</p>
<hr />
<h2 id="ept-和-iommu-的分工"><strong>1. EPT 和 IOMMU
的分工</strong></h2>
<h3 id="ept扩展页表"><strong>(1) EPT（扩展页表）</strong></h3>
<p>• <strong>作用</strong>：负责 <strong>CPU 访问内存时的 GPA→HPA
转换</strong>（即虚拟机内部的 MMU 页表转换）。 •
<strong>适用场景</strong>： • 虚拟机内部的 <strong>CPU
指令访问内存</strong>（如 <code>mov [rax], rbx</code>）。 •
<strong>软件模拟的设备</strong>（如 virtio）的 MMIO 访问。 •
<strong>不适用场景</strong>： • <strong>外设 DMA 操作</strong>（如 PCIe
设备直接读写内存），因为 DMA 不经过 CPU MMU，EPT 无法介入。</p>
<h3 id="iommu如-intel-vt-d-amd-vi"><strong>(2) IOMMU（如 Intel VT-d /
AMD-Vi）</strong></h3>
<p>• <strong>作用</strong>：负责 <strong>外设 DMA 的 GPA→HPA
转换</strong>，确保设备只能访问虚拟机被分配的内存。 •
<strong>适用场景</strong>： • PCIe 设备直通（如 GPU、NVMe SSD、网卡）的
DMA 操作。 • 防止设备越界访问其他虚拟机或宿主机的内存（DMA 攻击防护）。
• <strong>不适用场景</strong>： • CPU 访问内存（由 EPT 负责）。</p>
<hr />
<h2 id="为什么-ept-不能直接用于外设-dma"><strong>2. 为什么 EPT
不能直接用于外设 DMA？</strong></h2>
<p>• <strong>DMA 绕过 CPU MMU</strong>： • 外设（如网卡、GPU）进行 DMA
时，直接向内存控制器发起读写请求，<strong>不经过 CPU MMU</strong>，因此
EPT 无法拦截和转换地址。 • <strong>IOMMU 是硬件级 DMA
隔离机制</strong>： • IOMMU 位于 <strong>PCIe
设备和内存控制器之间</strong>，可以拦截所有 DMA 请求并转换地址。 •
如果只有 EPT 而没有 IOMMU，设备 DMA 会直接使用 <strong>GPA</strong> 作为
<strong>HPA</strong>，导致内存错乱。</p>
<hr />
<h2 id="无-iommu-时的-dma-行为"><strong>3. 无 IOMMU 时的 DMA
行为</strong></h2>
<p>如果 <strong>没有 IOMMU</strong>，设备 DMA 会直接使用
<strong>GPA</strong> 作为 <strong>HPA</strong>，导致：</p>
<ol type="1">
<li><strong>地址错乱</strong>： • 虚拟机内 <code>GPA 0x1000</code>
可能对应宿主机 <code>HPA 0x5000</code>（由 EPT 管理），但设备 DMA
会直接访问 <code>HPA 0x1000</code>（错误的物理地址）。</li>
<li><strong>内存污染</strong>： •
设备可能写入其他虚拟机或宿主机的内存（安全漏洞）。</li>
<li><strong>系统崩溃</strong>： • 错误的 DMA 访问可能导致宿主机内核
panic 或虚拟机异常退出。</li>
</ol>
<hr />
<h2 id="完整流程对比有无-iommu"><strong>4. 完整流程对比（有/无
IOMMU）</strong></h2>
<h3 id="有-iommu-的正常流程"><strong>(1) 有 IOMMU
的正常流程</strong></h3>
<pre><code class=" mermaid">flowchart TB
    subgraph 虚拟机
        A[设备 DMA 请求 GPA 0x1000] --&gt; B[IOMMU 转换]
    end
    subgraph 宿主机
        B --&gt; C[HPA 0x8000（正确地址）]
    end
</code></pre>
<p>• <strong>IOMMU 确保</strong>：设备 DMA 的 <code>GPA 0x1000</code>
被转换为正确的 <code>HPA 0x8000</code>。</p>
<h3 id="无-iommu-的错误流程"><strong>(2) 无 IOMMU
的错误流程</strong></h3>
<pre><code class=" mermaid">flowchart TB
    subgraph 虚拟机
        A[设备 DMA 请求 GPA 0x1000] --&gt; B[直接访问 HPA 0x1000]
    end
    subgraph 宿主机
        B --&gt; C[可能属于其他 VM 或宿主机内核]
    end
</code></pre>
<p>• <strong>无 IOMMU</strong>：设备 DMA 直接使用
<code>GPA 0x1000</code> 作为 <code>HPA 0x1000</code>，导致越界访问。</p>
<hr />
<h2 id="结论"><strong>5. 结论</strong></h2>
<p>• <strong>EPT 负责 CPU 访问内存的 GPA→HPA 转换</strong>（软件层面）。
• <strong>IOMMU 负责外设 DMA 的 GPA→HPA 转换</strong>（硬件层面）。 •
<strong>如果没有 IOMMU，EPT 无法保护 DMA
操作</strong>，设备会直接使用错误的 HPA，导致内存污染和安全问题。 •
<strong>IOMMU 是 PCIe 设备直通（PCI
Passthrough）的必备条件</strong>，否则无法安全使用 GPU、NVMe SSD
等高性能设备。</p>
<h3 id="简单总结"><strong>简单总结</strong></h3>
<table>
<thead>
<tr class="header">
<th>机制</th>
<th>作用范围</th>
<th>是否影响 DMA</th>
<th>是否影响 CPU 访问</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>EPT</strong></td>
<td>CPU MMU</td>
<td>❌ 不参与</td>
<td>✅ 负责 GPA→HPA</td>
</tr>
<tr class="even">
<td><strong>IOMMU</strong></td>
<td>PCIe 设备 DMA</td>
<td>✅ 负责 GPA→HPA</td>
<td>❌ 不参与</td>
</tr>
</tbody>
</table>
<p>因此，<strong>EPT 和 IOMMU
是互补的</strong>，两者共同确保虚拟机的内存访问（CPU +
设备）都能正确映射到宿主机的物理内存。</p>
<h2 id="iommu中会进行ioremap吗">iommu中会进行ioremap吗？</h2>
<p>在 Linux 内核中，<strong>IOMMU 和 <code>ioremap</code>
是两个不同的机制</strong>，但它们可能在某些场景下协同工作。以下是详细分析：</p>
<hr />
<h2 id="ioremap-的作用"><strong>1. <code>ioremap</code>
的作用</strong></h2>
<p><code>ioremap</code> 是 Linux 内核提供的函数，用于： •
<strong>将设备的 MMIO（Memory-Mapped
I/O）区域映射到内核虚拟地址空间</strong>，使内核可以访问设备的寄存器或内存。
• <strong>不涉及 DMA</strong>，仅用于 CPU 通过 load/store
指令访问设备寄存器。 • <strong>典型场景</strong>： • 设备驱动通过
<code>ioremap</code> 映射 PCI BAR 空间，读写设备控制寄存器。 •
例如：网卡驱动配置寄存器、GPU 驱动访问显存。</p>
<p><strong>示例代码</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> __iomem *regs = ioremap(phys_addr, size);<br>writel(value, regs + offset); <span class="hljs-comment">// 写入设备寄存器</span><br></code></pre></td></tr></table></figure>
<hr />
<h2 id="iommu-的作用"><strong>2. IOMMU 的作用</strong></h2>
<p>IOMMU 的核心功能是： • <strong>管理设备 DMA
的内存访问</strong>，将设备使用的 I/O
虚拟地址（IOVA）转换为物理地址（HPA）。 • <strong>不直接参与
<code>ioremap</code></strong>，但可能影响 MMIO
的物理地址访问（某些架构下）。 • <strong>典型场景</strong>： • PCIe
设备直通（Passthrough）时，隔离设备的 DMA 操作。 • 防止设备 DMA
越界访问（如 DMA 攻击）。</p>
<hr />
<h2 id="iommu-和-ioremap-的关系"><strong>3. IOMMU 和
<code>ioremap</code> 的关系</strong></h2>
<h3 id="一般情况下iommu-不介入-ioremap"><strong>(1) 一般情况下：IOMMU
不介入 <code>ioremap</code></strong></h3>
<p>• <code>ioremap</code> 是 <strong>CPU 访问 MMIO</strong> 的机制，而
IOMMU 管理的是 <strong>设备 DMA</strong>。 • <code>ioremap</code>
直接操作物理地址（绕过 IOMMU），因为 CPU
访问设备寄存器时不需要地址转换。</p>
<h3 id="特殊情况iommu-可能影响-mmio-访问"><strong>(2) 特殊情况：IOMMU
可能影响 MMIO 访问</strong></h3>
<p>在某些架构（如 ARM SMMU）或配置下： • 如果设备的 <strong>MMIO 区域被
IOMMU 隔离</strong>，内核可能需要先通过 IOMMU 映射，再使用
<code>ioremap</code>。 • 例如： • 在 <strong>ARM 系统</strong> 中，SMMU
可能对设备的 MMIO 也进行保护，此时 <code>ioremap</code>
需要确保物理地址可被 CPU 访问。 • 在 <strong>虚拟化环境</strong>
中，直通设备的 MMIO 可能需要额外的 IOMMU 配置。</p>
<h3 id="dma-相关dma_alloc_coherent-和-iommu"><strong>(3) DMA
相关：<code>dma_alloc_coherent</code> 和 IOMMU</strong></h3>
<p>• 如果设备需要通过 DMA 访问内存（而非 MMIO），驱动会使用
<code>dma_alloc_coherent</code>：</p>
<p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> *buf = dma_alloc_coherent(dev, size, &amp;dma_handle, GFP_KERNEL);<br></code></pre></td></tr></table></figure></p>
<p>• 该函数会返回 <strong>内核虚拟地址（<code>buf</code>）</strong> 和
<strong>设备可用的 DMA 地址（<code>dma_handle</code>）</strong>。 •
<strong>如果 IOMMU 启用</strong>，<code>dma_handle</code> 是 IOVA（IOMMU
转换后的地址），而非真实物理地址（HPA）。 • <strong>如果 IOMMU
禁用</strong>，<code>dma_handle</code> 直接是物理地址。</p>
<hr />
<h2 id="总结-4"><strong>4. 总结</strong></h2>
<table>

<thead>
<tr class="header">
<th>机制</th>
<th>作用范围</th>
<th>是否依赖 IOMMU？</th>
<th>典型 API</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong><code>ioremap</code></strong></td>
<td>CPU 访问设备 MMIO</td>
<td>❌ 通常不依赖</td>
<td><code>ioremap()</code>, <code>iowrite32()</code></td>
</tr>
<tr class="even">
<td><strong>IOMMU</strong></td>
<td>设备 DMA 地址转换</td>
<td>✅ 直接影响 DMA</td>
<td><code>dma_alloc_coherent()</code></td>
</tr>
<tr class="odd">
<td><strong>两者关系</strong></td>
<td>独立，但在某些架构下协同</td>
<td>MMIO 可能受 IOMMU 保护</td>
<td>架构相关（如 ARM SMMU）</td>
</tr>
</tbody>
</table>
<h3 id="关键结论"><strong>关键结论</strong></h3>
<ol type="1">
<li><strong><code>ioremap</code> 通常不涉及 IOMMU</strong>，因为它是 CPU
直接访问 MMIO 的机制。</li>
<li><strong>IOMMU 主要管理设备 DMA</strong>，但某些架构可能扩展其对 MMIO
的保护。</li>
<li>在编写设备驱动时： • 访问寄存器 → 用 <code>ioremap</code>。 • 分配
DMA 缓冲区 → 用 <code>dma_alloc_coherent</code>（受 IOMMU 影响）。</li>
</ol>
<h2 id="网卡收发包dma讲一下">网卡收发包dma讲一下</h2>
<h3 id="网卡收发包的-dma直接内存访问流程详解"><strong>网卡收发包的
DMA（直接内存访问）流程详解</strong></h3>
<p>网卡（NIC, Network Interface Card）通过 <strong>DMA（Direct Memory
Access）</strong> 技术高效地收发数据包，避免 CPU
频繁参与数据拷贝，从而提升网络性能。以下是详细流程：</p>
<hr />
<h2 id="基本概念"><strong>1. 基本概念</strong></h2>
<h3 id="dma-的作用"><strong>(1) DMA 的作用</strong></h3>
<p>• <strong>CPU 不直接参与数据搬运</strong>，而是由网卡直接读写内存。 •
<strong>减少 CPU 开销</strong>，提高吞吐量（如 10G/25G/100G
高速网络）。</p>
<h3 id="关键组件"><strong>(2) 关键组件</strong></h3>
<table>

<thead>
<tr class="header">
<th>组件</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>网卡（NIC）</strong></td>
<td>负责物理层数据收发，通过 DMA 与内存交互。</td>
</tr>
<tr class="even">
<td><strong>驱动（Driver）</strong></td>
<td>管理网卡，分配 DMA 缓冲区，处理中断。</td>
</tr>
<tr class="odd">
<td><strong>环形队列（Ring）</strong></td>
<td>存储数据包描述符（Descriptor），指向 DMA 缓冲区地址。</td>
</tr>
<tr class="even">
<td><strong>DMA 缓冲区</strong></td>
<td>存放实际数据包的内核内存区域，由网卡直接访问。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="收包流程rx-receive"><strong>2. 收包流程（Rx,
Receive）</strong></h2>
<h3 id="驱动初始化"><strong>(1) 驱动初始化</strong></h3>
<ol type="1">
<li><strong>分配 DMA
缓冲区</strong>（<code>dma_alloc_coherent</code>）： •
内核为收包分配一组内存块（通常为 <code>sk_buff</code> 或
<code>page</code> 结构）。 • 如果启用 <strong>IOMMU</strong>，返回的是
<strong>IOVA（I/O Virtual
Address）</strong>，否则是物理地址（HPA）。</li>
<li><strong>填充描述符到 Rx Ring</strong>： • 每个描述符指向一个 DMA
缓冲区地址（如 <code>buf1 → 0x1000</code>,
<code>buf2 → 0x2000</code>）。 • 网卡通过 PCIe 总线读取这些描述符。</li>
</ol>
<h3 id="网卡收包"><strong>(2) 网卡收包</strong></h3>
<ol type="1">
<li><strong>数据包到达网卡</strong>： •
网卡从物理端口接收数据（如以太网帧）。</li>
<li><strong>DMA 写入内存</strong>： • 网卡根据 Rx Ring
中的描述符，找到空闲的 DMA 缓冲区（如 <code>buf1</code>）。 • 直接通过
DMA 将数据写入 <code>buf1</code>（地址 <code>0x1000</code>）。</li>
<li><strong>更新描述符状态</strong>： •
网卡标记描述符为“已填充”，并可能触发中断（MSI-X）通知 CPU。</li>
</ol>
<h3 id="内核处理"><strong>(3) 内核处理</strong></h3>
<ol type="1">
<li><strong>CPU 收到中断</strong>： • 驱动检查 Rx Ring，发现
<code>buf1</code> 有新数据。</li>
<li><strong>解析数据包</strong>： • 将 <code>buf1</code> 的数据封装为
<code>sk_buff</code>，传递给网络协议栈（如 IP/TCP 处理）。</li>
<li><strong>回收缓冲区</strong>： • 驱动重新填充 <code>buf1</code> 到 Rx
Ring，供下一次收包使用。</li>
</ol>
<pre><code class=" mermaid">flowchart LR
    A[数据包到达网卡] --&gt; B[网卡 DMA 写入 Rx 缓冲区]
    B --&gt; C[网卡触发中断]
    C --&gt; D[CPU 处理数据包]
    D --&gt; E[协议栈处理]
    E --&gt; F[驱动回收缓冲区]
</code></pre>
<hr />
<h2 id="发包流程tx-transmit"><strong>3. 发包流程（Tx,
Transmit）</strong></h2>
<h3 id="驱动准备数据"><strong>(1) 驱动准备数据</strong></h3>
<ol type="1">
<li><strong>协议栈构造数据包</strong>： • 应用数据经过 TCP/IP
封装后，生成 <code>sk_buff</code>。</li>
<li><strong>分配 DMA 缓冲区</strong>： • 驱动将 <code>sk_buff</code>
的数据映射到 DMA 区域（<code>dma_map_single</code>）。 • 如果启用
<strong>IOMMU</strong>，会生成 IOVA，否则直接使用物理地址。</li>
<li><strong>填充描述符到 Tx Ring</strong>： • 描述符指向数据包的 DMA
地址和长度（如 <code>buf_tx → 0x3000</code>）。</li>
</ol>
<h3 id="网卡发包"><strong>(2) 网卡发包</strong></h3>
<ol type="1">
<li><strong>驱动触发网卡</strong>： •
通过写寄存器通知网卡“有数据待发送”。</li>
<li><strong>网卡读取 Tx Ring</strong>： • 找到待发送的描述符（如
<code>buf_tx</code>）。</li>
<li><strong>DMA 读取内存</strong>： • 网卡从 <code>0x3000</code>
读取数据，通过物理端口发送。</li>
</ol>
<h3 id="完成通知"><strong>(3) 完成通知</strong></h3>
<ol type="1">
<li><strong>网卡发送完成</strong>： •
数据发送后，网卡更新描述符状态，并可能触发中断。</li>
<li><strong>驱动回收资源</strong>： • 释放 DMA
映射（<code>dma_unmap_single</code>），回收 <code>sk_buff</code>。</li>
</ol>
<pre><code class=" mermaid">flowchart LR
    A[协议栈构造 sk_buff] --&gt; B[驱动映射 DMA 缓冲区]
    B --&gt; C[填充 Tx Ring]
    C --&gt; D[网卡 DMA 读取数据]
    D --&gt; E[发送到网络]
    E --&gt; F[中断通知完成]
</code></pre>
<hr />
<h2 id="关键优化技术"><strong>4. 关键优化技术</strong></h2>
<h3 id="多队列rss-receive-side-scaling"><strong>(1) 多队列（RSS, Receive
Side Scaling）</strong></h3>
<p>• <strong>每个 CPU 核心绑定独立的 Rx/Tx
队列</strong>，避免锁竞争，提升多核性能。</p>
<h3 id="零拷贝zero-copy"><strong>(2) 零拷贝（Zero-Copy）</strong></h3>
<p>• <strong>用户态直接访问 DMA 缓冲区</strong>（如
DPDK、XDP），跳过内核协议栈。</p>
<h3 id="中断合并interrupt-coalescing"><strong>(3) 中断合并（Interrupt
Coalescing）</strong></h3>
<p>• 网卡积累多个数据包后触发一次中断，减少 CPU 负载。</p>
<h3 id="iommu-隔离"><strong>(4) IOMMU 隔离</strong></h3>
<p>• 防止网卡 DMA 越界访问其他内存（安全关键）。</p>
<hr />
<h2 id="无-dma-的对比pio-模式"><strong>5. 无 DMA 的对比（PIO
模式）</strong></h2>
<p>如果网卡不使用 DMA，只能通过 <strong>PIO（Programmed
I/O）</strong>：</p>
<ol type="1">
<li><strong>CPU 必须逐字节读写网卡寄存器</strong>，性能极低。</li>
<li><strong>仅用于早期低速网卡（如 10Mbps）</strong>，现代网卡均依赖
DMA。</li>
</ol>
<hr />
<h2 id="总结-5"><strong>6. 总结</strong></h2>
<table>

<thead>
<tr class="header">
<th>步骤</th>
<th>收包（Rx）</th>
<th>发包（Tx）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>1. 准备</strong></td>
<td>驱动分配 DMA 缓冲区，填充 Rx Ring</td>
<td>协议栈构造数据包，映射 DMA</td>
</tr>
<tr class="even">
<td><strong>2. 硬件</strong></td>
<td>网卡 DMA 写入内存，触发中断</td>
<td>网卡 DMA 读取内存，发送数据</td>
</tr>
<tr class="odd">
<td><strong>3. 软件</strong></td>
<td>CPU 处理数据包，回收缓冲区</td>
<td>CPU 释放资源</td>
</tr>
</tbody>
</table>
<p>• <strong>DMA 核心作用</strong>：网卡直接访问内存，减少 CPU 参与。 •
<strong>IOMMU 的作用</strong>：保护 DMA 操作的安全性（防止越界访问）。 •
<strong>性能关键</strong>：多队列、零拷贝、中断合并。</p>
<h2 id="进一步给出网卡收发包流程图">进一步给出网卡收发包流程图</h2>
<p>以下是 <strong>网卡收发包 DMA 流程的详细流程图</strong>，分为
<strong>收包（Rx）</strong> 和 <strong>发包（Tx）</strong>
两个部分，并标注关键步骤和硬件/软件交互：</p>
<hr />
<h3 id="收包流程rx"><strong>1. 收包流程（Rx）</strong></h3>
<pre><code class=" mermaid">flowchart TB
    subgraph 驱动初始化
        A[分配DMA缓冲区] --&gt; B[填充Rx Ring描述符]
    end
    subgraph 网卡收包
        C[数据包到达网卡] --&gt; D[网卡DMA写入内存]
        D --&gt; E[更新描述符状态]
        E --&gt; F[触发中断通知CPU]
    end
    subgraph 内核处理
        F --&gt; G[CPU读取Rx Ring]
        G --&gt; H[解析数据包（sk_buff）]
        H --&gt; I[传递给协议栈（IP/TCP）]
        I --&gt; J[回收缓冲区到Rx Ring]
    end
</code></pre>
<h4 id="关键步骤说明"><strong>关键步骤说明</strong></h4>
<ol type="1">
<li><strong>驱动初始化</strong>：<br />
• 分配 DMA 缓冲区（如 <code>dma_alloc_coherent</code>），填充到 Rx Ring
描述符中。</li>
<li><strong>网卡收包</strong>：<br />
• 网卡通过 DMA 将数据直接写入内存，更新描述符并触发中断。</li>
<li><strong>内核处理</strong>：<br />
• CPU 从 Rx Ring 读取数据，交给协议栈处理，最后回收缓冲区。</li>
</ol>
<hr />
<h3 id="发包流程tx"><strong>2. 发包流程（Tx）</strong></h3>
<pre><code class=" mermaid">flowchart TB
    subgraph 协议栈准备
        A[构造数据包（sk_buff）] --&gt; B[映射DMA缓冲区]
        B --&gt; C[填充Tx Ring描述符]
    end
    subgraph 网卡发包
        C --&gt; D[网卡读取Tx Ring]
        D --&gt; E[网卡DMA从内存读取数据]
        E --&gt; F[通过物理端口发送]
        F --&gt; G[发送完成中断]
    end
    subgraph 驱动清理
        G --&gt; H[CPU释放DMA映射]
        H --&gt; I[回收sk_buff]
    end
</code></pre>
<h4 id="关键步骤说明-1"><strong>关键步骤说明</strong></h4>
<ol type="1">
<li><strong>协议栈准备</strong>：<br />
• 将数据包映射到 DMA 缓冲区（如
<code>dma_map_single</code>），描述符填入 Tx Ring。</li>
<li><strong>网卡发包</strong>：<br />
• 网卡从 Tx Ring 获取描述符，通过 DMA 读取内存数据并发送。</li>
<li><strong>驱动清理</strong>：<br />
• 发送完成后，CPU 释放 DMA 映射并回收资源。</li>
</ol>
<hr />
<h3 id="完整收发包交互图"><strong>3. 完整收发包交互图</strong></h3>
<pre><code class=" mermaid">flowchart LR
    subgraph 收包Rx
        A[网卡DMA写内存] --&gt; B[CPU处理]
    end
    subgraph 发包Tx
        C[CPU填充Tx Ring] --&gt; D[网卡DMA读内存]
    end
    B --&gt;|协议栈| C
    D --&gt;|发送完成| A
</code></pre>
<h4 id="核心交互"><strong>核心交互</strong></h4>
<p>• <strong>绿色箭头</strong>：数据流向（收包是网卡→内存→CPU，发包是
CPU→内存→网卡）。<br />
• <strong>DMA 双向操作</strong>：<br />
• 收包：网卡 DMA <strong>写</strong>内存。<br />
• 发包：网卡 DMA <strong>读</strong>内存。</p>
<hr />
<h3 id="关键组件关系图"><strong>4. 关键组件关系图</strong></h3>
<pre><code class=" mermaid">flowchart TD
    NIC[网卡] --&gt;|DMA| MEM[(内存)]
    MEM --&gt;|中断| CPU[CPU/驱动]
    CPU --&gt;|填充描述符| Ring[Rx/Tx Ring]
    Ring --&gt;|DMA地址| NIC
</code></pre>
<h4 id="组件角色"><strong>组件角色</strong></h4>
<p>• <strong>网卡</strong>：发起 DMA 读写，触发中断。<br />
• <strong>内存</strong>：存储数据包（DMA 缓冲区）。<br />
• <strong>CPU/驱动</strong>：管理描述符，处理中断。<br />
• <strong>Ring</strong>：描述符队列，协调硬件和软件。</p>
<hr />
<h3 id="总结-6"><strong>总结</strong></h3>
<ol type="1">
<li><strong>DMA 核心作用</strong>：<br />
• 收包：网卡直接写内存，CPU 后处理。<br />
• 发包：CPU 准备数据，网卡直接读内存。<br />
</li>
<li><strong>性能关键</strong>：<br />
• 减少 CPU 拷贝（零拷贝）、多队列并行、中断合并。<br />
</li>
<li><strong>安全依赖</strong>：<br />
• IOMMU 确保 DMA 只能访问指定内存区域。</li>
</ol>
<p>通过流程图可以清晰看到 <strong>数据如何绕过 CPU
直接流动</strong>，这是高性能网络的核心设计！</p>
<h2 id="网卡驱动中包含dma代码">网卡驱动中包含dma代码？</h2>
<p>是的，<strong>网卡驱动中必须包含DMA相关的代码</strong>，因为现代网卡依赖DMA（直接内存访问）来高效传输数据。以下是网卡驱动中DMA代码的核心组成部分及其作用：</p>
<hr />
<h3 id="dma在网卡驱动中的核心作用"><strong>1.
DMA在网卡驱动中的核心作用</strong></h3>
<p>•
<strong>数据缓冲区管理</strong>：驱动需要为网卡分配DMA可访问的内存区域（用于收发包）。
•
<strong>地址映射</strong>：将内核内存的物理地址（或IOVA）传递给网卡，使其能直接读写。
•
<strong>同步机制</strong>：确保CPU和网卡对共享内存的访问一致性（如内存屏障、缓存刷新）。</p>
<hr />
<h3 id="网卡驱动中的关键dma代码"><strong>2.
网卡驱动中的关键DMA代码</strong></h3>
<h4 id="dma缓冲区分配"><strong>(1) DMA缓冲区分配</strong></h4>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 分配DMA一致性内存（收包/发包缓冲区）</span><br><span class="hljs-type">dma_addr_t</span> dma_handle;<br><span class="hljs-type">void</span> *buffer = dma_alloc_coherent(dev, size, &amp;dma_handle, GFP_KERNEL);<br></code></pre></td></tr></table></figure>
<p>•
<strong>作用</strong>：分配一段物理连续的内存，并返回<strong>内核虚拟地址</strong>（<code>buffer</code>）和<strong>设备可用的DMA地址</strong>（<code>dma_handle</code>）。
•
<strong>IOMMU支持</strong>：若系统启用IOMMU，<code>dma_handle</code>是IOVA（设备看到的虚拟地址），否则是物理地址。</p>
<h4 id="描述符队列ring初始化"><strong>(2)
描述符队列（Ring）初始化</strong></h4>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">descriptor</span> &#123;</span><br>    <span class="hljs-type">dma_addr_t</span> dma_addr;  <span class="hljs-comment">// 缓冲区DMA地址</span><br>    u32 length;           <span class="hljs-comment">// 数据长度</span><br>    u32 status;           <span class="hljs-comment">// 状态（如是否已使用）</span><br>&#125;;<br><br><span class="hljs-comment">// 填充Rx/Tx Ring描述符</span><br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; ring_size; i++) &#123;<br>    ring[i].dma_addr = dma_map_single(dev, skb-&gt;data, skb-&gt;len, DMA_FROM_DEVICE);<br>    ring[i].length = skb-&gt;len;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>•
<strong>作用</strong>：描述符是驱动和网卡之间的“合约”，告诉网卡从哪里读写数据。</p>
<h4 id="dma地址映射与解映射"><strong>(3)
DMA地址映射与解映射</strong></h4>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 映射数据包内存供网卡DMA访问（发包时）</span><br><span class="hljs-type">dma_addr_t</span> dma_addr = dma_map_single(dev, skb-&gt;data, skb-&gt;len, DMA_TO_DEVICE);<br><br><span class="hljs-comment">// 解映射（数据发送完成后）</span><br>dma_unmap_single(dev, dma_addr, skb-&gt;len, DMA_TO_DEVICE);<br></code></pre></td></tr></table></figure>
<p>• <strong>方向参数</strong>： •
<code>DMA_TO_DEVICE</code>：数据从内存到网卡（发包）。 •
<code>DMA_FROM_DEVICE</code>：数据从网卡到内存（收包）。 •
<strong>缓存一致性</strong>：<code>dma_map_single</code>会触发缓存刷新（如ARM的<code>cache invalidate</code>）。</p>
<h4 id="中断处理与dma同步"><strong>(4) 中断处理与DMA同步</strong></h4>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 中断处理函数（收包完成后）</span><br><span class="hljs-type">irqreturn_t</span> <span class="hljs-title function_">irq_handler</span><span class="hljs-params">(<span class="hljs-type">int</span> irq, <span class="hljs-type">void</span> *dev_id)</span> &#123;<br>    <span class="hljs-comment">// 检查Rx Ring中哪些描述符已被网卡填充</span><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; rx_ring_size; i++) &#123;<br>        <span class="hljs-keyword">if</span> (rx_ring[i].status == READY) &#123;<br>            <span class="hljs-comment">// 将数据传递给协议栈</span><br>            netif_receive_skb(skb);<br>            <span class="hljs-comment">// 重新填充描述符（回收缓冲区）</span><br>            rx_ring[i].dma_addr = dma_map_single(...);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<hr />
<h3 id="典型dma工作流程以收包为例"><strong>3.
典型DMA工作流程（以收包为例）</strong></h3>
<pre><code class=" mermaid">sequenceDiagram
    participant 驱动
    participant 网卡
    participant 内存

    驱动-&gt;&gt;内存: dma_alloc_coherent()分配缓冲区
    驱动-&gt;&gt;网卡: 将DMA地址写入Rx Ring描述符
    网卡-&gt;&gt;内存: DMA写入数据包（直接访问物理内存/IOVA）
    网卡-&gt;&gt;驱动: 触发中断
    驱动-&gt;&gt;内存: 读取数据并传递给协议栈
    驱动-&gt;&gt;网卡: 回收描述符，准备下一次收包
</code></pre>
<hr />
<h3 id="不同场景的dma代码差异"><strong>4.
不同场景的DMA代码差异</strong></h3>
<table>

<thead>
<tr class="header">
<th><strong>场景</strong></th>
<th><strong>DMA代码差异</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>启用IOMMU</strong></td>
<td><code>dma_alloc_coherent</code>返回IOVA，驱动无需关心物理地址。</td>
</tr>
<tr class="even">
<td><strong>禁用IOMMU</strong></td>
<td><code>dma_alloc_coherent</code>返回物理地址，驱动直接操作硬件寄存器。</td>
</tr>
<tr class="odd">
<td><strong>多队列网卡（RSS）</strong></td>
<td>每个队列独立分配DMA缓冲区，避免竞争。</td>
</tr>
<tr class="even">
<td><strong>零拷贝（XDP/DPDK）</strong></td>
<td>用户态直接操作DMA缓冲区，绕过内核协议栈（需特殊内存映射）。</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="常见问题与调试"><strong>5. 常见问题与调试</strong></h3>
<h4 id="dma地址错误"><strong>(1) DMA地址错误</strong></h4>
<p>• <strong>现象</strong>：网卡访问错误内存导致系统崩溃。 •
<strong>调试</strong>：</p>
<p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看DMA映射情况（Linux内核调试）</span><br><span class="hljs-built_in">cat</span> /proc/iomem<br>dmesg | grep -i dma<br></code></pre></td></tr></table></figure></p>
<h4 id="性能优化"><strong>(2) 性能优化</strong></h4>
<p>•
<strong>预分配缓冲区</strong>：启动时一次性分配大量DMA内存，避免运行时动态分配。
•
<strong>缓存对齐</strong>：使用<code>kmalloc</code>时指定<code>GFP_DMA</code>标志，确保内存位于DMA可访问区域。</p>
<hr />
<h3 id="总结-7"><strong>6. 总结</strong></h3>
<p>•
<strong>网卡驱动必须实现DMA逻辑</strong>：包括内存分配、地址映射、同步和中断处理。
•
<strong>核心API</strong>：<code>dma_alloc_coherent</code>、<code>dma_map_single</code>、<code>dma_unmap_single</code>。
•
<strong>安全依赖</strong>：IOMMU防止设备越界访问，但驱动仍需正确管理生命周期。</p>
<p>通过DMA，网卡驱动能够实现<strong>高性能、低CPU占用</strong>的数据传输，这是现代网络栈（如10G/100G网卡）的基础。</p>
<h2 id="dma是个独立的子系统">dma是个独立的子系统？</h2>
<p>在 Linux 内核中，<strong>DMA（Direct Memory
Access）并不是一个完全独立的子系统</strong>，而是一个<strong>跨模块的核心机制</strong>，由多个内核组件协同实现。以下是详细分析：</p>
<hr />
<h3 id="dma-的模块化实现"><strong>1. DMA 的模块化实现</strong></h3>
<p>DMA 的功能分散在内核多个子系统中，各司其职：</p>
<table>

<thead>
<tr class="header">
<th><strong>组件</strong></th>
<th><strong>职责</strong></th>
<th><strong>所属子系统</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>DMA 引擎框架</strong></td>
<td>提供通用 DMA 控制器驱动接口（如 PL330、Intel IOAT）</td>
<td><code>drivers/dma/</code></td>
</tr>
<tr class="even">
<td><strong>DMA 内存映射 API</strong></td>
<td>提供 <code>dma_alloc_coherent</code>、<code>dma_map_single</code>
等函数</td>
<td>内核内存管理（MM）</td>
</tr>
<tr class="odd">
<td><strong>IOMMU 子系统</strong></td>
<td>管理设备 DMA 地址转换（VT-d/AMD-Vi）</td>
<td><code>drivers/iommu/</code></td>
</tr>
<tr class="even">
<td><strong>设备驱动</strong></td>
<td>调用 DMA API 实现具体设备的 DMA 操作（如网卡、NVMe）</td>
<td>各设备驱动模块（如 <code>drivers/net/</code>）</td>
</tr>
<tr class="odd">
<td><strong>PCI 核心层</strong></td>
<td>处理 PCI 设备的 DMA 配置（如 BAR 空间、MSI-X 中断与 DMA 关联）</td>
<td><code>drivers/pci/</code></td>
</tr>
</tbody>
</table>
<hr />
<h3 id="为什么-dma-不是独立子系统"><strong>2. 为什么 DMA
不是独立子系统？</strong></h3>
<h4 id="功能跨越多层"><strong>(1) 功能跨越多层</strong></h4>
<p>• <strong>硬件依赖性强</strong>：不同 DMA 控制器（如嵌入式 SoC 的
PL330 vs. 服务器的 Intel IOAT）需要不同驱动。 •
<strong>与内存管理深度耦合</strong>：DMA 缓冲区分配依赖 <code>mm</code>
子系统（如 <code>GFP_DMA</code> 标志）。 •
<strong>设备驱动集成</strong>：每个设备（网卡、磁盘）的 DMA
操作由各自驱动实现。</p>
<h4 id="无统一的dma-核心"><strong>(2) 无统一的“DMA 核心”</strong></h4>
<p>• 内核没有类似 <code>kernel/dma/</code> 的独立目录，而是通过
<strong>API 抽象</strong>（如
<code>include/linux/dma-mapping.h</code>）供其他模块调用。</p>
<hr />
<h3 id="关键-dma-相关子系统详解"><strong>3. 关键 DMA
相关子系统详解</strong></h3>
<h4 id="dma-引擎框架driversdma"><strong>(1) DMA
引擎框架（<code>drivers/dma/</code>）</strong></h4>
<p>• <strong>作用</strong>：为 <strong>专用 DMA
控制器</strong>（非设备内置 DMA）提供驱动框架。 •
<strong>示例</strong>：</p>
<p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 注册一个 DMA 控制器驱动（如 PL330）</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dma_device</span> *<span class="hljs-title">dma_dev</span> =</span> alloc_dma_device();<br>dma_async_device_register(dma_dev);<br></code></pre></td></tr></table></figure></p>
<p>• <strong>适用场景</strong>：内存拷贝加速（如
<code>async_tx</code>）、音频数据传输等。</p>
<h4 id="dma-内存映射-api"><strong>(2) DMA 内存映射 API</strong></h4>
<p>• <strong>核心函数</strong>：</p>
<p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 分配一致性 DMA 内存</span><br><span class="hljs-type">void</span> *<span class="hljs-title function_">dma_alloc_coherent</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> device *dev, <span class="hljs-type">size_t</span> size, <span class="hljs-type">dma_addr_t</span> *dma_handle, <span class="hljs-type">gfp_t</span> flag)</span>;<br><br><span class="hljs-comment">// 映射单页内存供设备 DMA</span><br><span class="hljs-type">dma_addr_t</span> <span class="hljs-title function_">dma_map_single</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> device *dev, <span class="hljs-type">void</span> *ptr, <span class="hljs-type">size_t</span> size, <span class="hljs-keyword">enum</span> dma_data_direction dir)</span>;<br></code></pre></td></tr></table></figure></p>
<p>• <strong>底层依赖</strong>： • 若启用 IOMMU，调用
<code>iommu_dma_alloc()</code>。 • 若无 IOMMU，直接返回物理地址。</p>
<h4 id="iommu-子系统driversiommu"><strong>(3) IOMMU
子系统（<code>drivers/iommu/</code>）</strong></h4>
<p>• <strong>功能</strong>：将设备 DMA
地址（IOVA）转换为物理地址（HPA），提供隔离保护。 • <strong>与 DMA
的关系</strong>：</p>
<p><pre><code class=" mermaid">flowchart LR
  A[设备DMA请求 IOVA] --&gt; B&#123;是否启用IOMMU?&#125;
  B --&gt;|是| C[IOMMU硬件转换 HPA]
  B --&gt;|否| D[直接使用物理地址]
</code></pre></p>
<h4 id="设备驱动中的-dma-实现"><strong>(4) 设备驱动中的 DMA
实现</strong></h4>
<p>以网卡驱动（如
<code>drivers/net/ethernet/intel/igb/igb_main.c</code>）为例：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 初始化 Rx 环的 DMA 缓冲区</span><br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; rx_ring-&gt;count; i++) &#123;<br>    rx_ring-&gt;desc[i].addr = dma_map_single(dev, skb-&gt;data, size, DMA_FROM_DEVICE);<br>&#125;<br></code></pre></td></tr></table></figure>
<hr />
<h3 id="dma-工作流程示例以网卡收包为例"><strong>4. DMA
工作流程示例（以网卡收包为例）</strong></h3>
<pre><code class=" mermaid">sequenceDiagram
    participant 驱动
    participant DMA API
    participant IOMMU
    participant 网卡

    驱动-&gt;&gt;DMA API: dma_alloc_coherent()
    DMA API-&gt;&gt;IOMMU: 分配IOVA（若启用）
    DMA API--&gt;&gt;驱动: 返回虚拟地址和DMA句柄
    驱动-&gt;&gt;网卡: 将DMA地址写入描述符环
    网卡-&gt;&gt;IOMMU: DMA请求（使用IOVA）
    IOMMU-&gt;&gt;内存: 转换为HPA并访问
    内存--&gt;&gt;网卡: 返回数据
    网卡-&gt;&gt;驱动: 中断通知完成
</code></pre>
<hr />
<h3 id="调试与监控"><strong>5. 调试与监控</strong></h3>
<h4 id="查看-dma-内存使用"><strong>(1) 查看 DMA 内存使用</strong></h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 显示 DMA 内存区域</span><br><span class="hljs-built_in">cat</span> /proc/iomem | grep DMA<br><br><span class="hljs-comment"># 监控 DMA 映射泄漏（内核配置 CONFIG_DMA_API_DEBUG）</span><br><span class="hljs-built_in">echo</span> 1 &gt; /sys/kernel/debug/dma-api/leak<br></code></pre></td></tr></table></figure>
<h4 id="跟踪-iommu-活动"><strong>(2) 跟踪 IOMMU 活动</strong></h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 启用 IOMMU 调试日志</span><br>dmesg | grep -i iommu<br></code></pre></td></tr></table></figure>
<hr />
<h3 id="总结-8"><strong>6. 总结</strong></h3>
<p>• <strong>DMA
是跨模块机制</strong>：依赖内存管理、IOMMU、设备驱动等多个子系统协作。 •
<strong>无独立子系统</strong>：通过 API 抽象和硬件驱动分散实现。 •
<strong>核心价值</strong>：为设备提供高效、安全的内存直接访问能力，是高性能
I/O 的基石。</p>
<h2 id="dma本身也是个外设">dma本身也是个外设？</h2>
<p>DMA（Direct Memory
Access）<strong>既可以是独立的外设，也可以是集成在其他硬件模块中的功能</strong>，具体取决于系统设计。以下是详细分类和解释：</p>
<hr />
<h3 id="作为独立外设的dma控制器"><strong>1.
作为独立外设的DMA控制器</strong></h3>
<h4 id="典型场景"><strong>(1) 典型场景</strong></h4>
<p>• <strong>嵌入式系统</strong>（如STM32、Zynq SoC）<br />
独立的DMA控制器（如ARM的PL080、PL330）作为片上外设存在，专门负责数据搬运。
• <strong>x86平台的历史设计</strong><br />
早期的ISA DMA控制器（如Intel 8237）用于软盘、声卡等低速设备。</p>
<h4 id="工作方式"><strong>(2) 工作方式</strong></h4>
<p>• <strong>CPU配置DMA控制器</strong>：<br />
通过寄存器设置源地址、目标地址、传输长度等参数。 •
<strong>触发传输</strong>：<br />
外设（如UART、ADC）发出请求信号，DMA控制器接管总线，直接完成内存与外设间的数据传输。
• <strong>中断通知</strong>：<br />
传输完成后，DMA控制器通过中断通知CPU。</p>
<h4 id="代码示例linux内核"><strong>(3)
代码示例（Linux内核）</strong></h4>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 注册DMA控制器驱动（PL330示例）</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dma_device</span> *<span class="hljs-title">pl330_dev</span> =</span> alloc_dma_device();<br>dma_async_device_register(pl330_dev);<br><br><span class="hljs-comment">// 发起DMA传输</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dma_async_tx_descriptor</span> *<span class="hljs-title">tx</span> =</span> dma_dev-&gt;device_prep_dma_memcpy(<br>    dma_chan, dest, src, size, flags);<br>dmaengine_submit(tx);<br>dma_async_issue_pending(dma_chan);<br></code></pre></td></tr></table></figure>
<hr />
<h3 id="集成在其他硬件中的dma引擎"><strong>2.
集成在其他硬件中的DMA引擎</strong></h3>
<h4 id="现代高性能设备"><strong>(1) 现代高性能设备</strong></h4>
<p>• <strong>网卡（NIC）</strong>、<strong>NVMe
SSD</strong>、<strong>GPU</strong>等设备内置DMA引擎，无需外部DMA控制器。
• <strong>工作流程</strong>：</p>
<ol type="1">
<li>驱动分配DMA缓冲区（如<code>dma_alloc_coherent</code>）。<br />
</li>
<li>将缓冲区地址写入设备寄存器。<br />
</li>
<li>设备直接通过PCIe总线发起DMA读写。</li>
</ol>
<h4 id="优势"><strong>(2) 优势</strong></h4>
<p>• <strong>低延迟</strong>：省去独立DMA控制器的中间环节。<br />
• <strong>高吞吐</strong>：支持并行多队列DMA（如网卡的RSS）。</p>
<h4 id="代码示例网卡驱动"><strong>(3) 代码示例（网卡驱动）</strong></h4>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 网卡驱动映射DMA缓冲区</span><br><span class="hljs-type">dma_addr_t</span> dma_addr = dma_map_single(dev, skb-&gt;data, skb-&gt;len, DMA_TO_DEVICE);<br><br><span class="hljs-comment">// 将DMA地址写入网卡寄存器</span><br>writel(dma_addr, nic_reg_base + TX_DESC_ADDR);<br></code></pre></td></tr></table></figure>
<hr />
<h3 id="dma的硬件实现差异"><strong>3. DMA的硬件实现差异</strong></h3>
<table>

<thead>
<tr class="header">
<th><strong>类型</strong></th>
<th><strong>独立DMA控制器</strong></th>
<th><strong>集成DMA引擎</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>典型硬件</strong></td>
<td>ARM PL330, Intel 8237</td>
<td>网卡（Intel I350）、NVMe SSD</td>
</tr>
<tr class="even">
<td><strong>总线占用</strong></td>
<td>需要接管系统总线</td>
<td>通过PCIe/NVLink等直接访问内存</td>
</tr>
<tr class="odd">
<td><strong>灵活性</strong></td>
<td>可服务多个外设</td>
<td>仅服务于所属设备</td>
</tr>
<tr class="even">
<td><strong>性能</strong></td>
<td>较低（共享带宽）</td>
<td>高（专用通道）</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="操作系统视角的dma"><strong>4. 操作系统视角的DMA</strong></h3>
<h4 id="内核抽象"><strong>(1) 内核抽象</strong></h4>
<p>• <strong>DMA API统一接口</strong>：<br />
无论DMA是独立外设还是集成功能，驱动均使用相同的API（如<code>dma_map_single</code>）。
• <strong>IOMMU介入</strong>：<br />
若系统有IOMMU，设备DMA地址会被转换为物理地址，对设备透明。</p>
<h4 id="设备树描述嵌入式系统"><strong>(2)
设备树描述（嵌入式系统）</strong></h4>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-comment">// 独立DMA控制器的设备树节点（ARM PL330示例）</span><br><span class="hljs-symbol">dma:</span> <span class="hljs-title class_">dma@4e000000</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">compatible</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;arm,pl330&quot;</span><span class="hljs-punctuation">;</span><br>    <span class="hljs-attr">reg</span> <span class="hljs-operator">=</span> <span class="hljs-params">&lt;<span class="hljs-number">0x4e000000</span> <span class="hljs-number">0x1000</span>&gt;</span><span class="hljs-punctuation">;</span><br>    <span class="hljs-attr">interrupts</span> <span class="hljs-operator">=</span> <span class="hljs-params">&lt;<span class="hljs-number">0</span> <span class="hljs-number">34</span> <span class="hljs-number">4</span>&gt;</span><span class="hljs-punctuation">;</span><br>    <span class="hljs-meta">#dma-cells = &lt;1&gt;;</span><br><span class="hljs-punctuation">&#125;;</span><br><br><span class="hljs-comment">// 使用DMA的外设节点（如UART）</span><br><span class="hljs-symbol">uart0:</span> <span class="hljs-title class_">serial@49000000</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">compatible</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;ti,omap3-uart&quot;</span><span class="hljs-punctuation">;</span><br>    <span class="hljs-attr">dmas</span> <span class="hljs-operator">=</span> <span class="hljs-params">&lt;<span class="hljs-variable">&amp;dma</span> <span class="hljs-number">12</span>&gt;</span>, <span class="hljs-params">&lt;<span class="hljs-variable">&amp;dma</span> <span class="hljs-number">13</span>&gt;</span><span class="hljs-punctuation">;</span>  <span class="hljs-comment">// Tx和Rx通道</span><br>    <span class="hljs-attr">dma-names</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;tx&quot;</span>, <span class="hljs-string">&quot;rx&quot;</span><span class="hljs-punctuation">;</span><br><span class="hljs-punctuation">&#125;;</span><br></code></pre></td></tr></table></figure>
<hr />
<h3 id="常见问题"><strong>5. 常见问题</strong></h3>
<h4 id="为什么需要独立dma控制器"><strong>(1)
为什么需要独立DMA控制器？</strong></h4>
<p>•
<strong>历史原因</strong>：早期CPU性能有限，卸载数据搬运任务可提高效率。<br />
•
<strong>资源共享</strong>：为多个低速外设（如UART、SPI）提供统一DMA服务。</p>
<h4 id="现代设备为何集成dma"><strong>(2)
现代设备为何集成DMA？</strong></h4>
<p>•
<strong>性能需求</strong>：高速设备（如40G网卡）需要专属DMA通道避免竞争。<br />
• <strong>简化设计</strong>：减少系统总线拥塞，降低延迟。</p>
<h4 id="如何判断dma是否独立"><strong>(3)
如何判断DMA是否独立？</strong></h4>
<p>•
<strong>查芯片手册</strong>：若存在独立的DMA控制器章节（如PL330），则为独立外设。<br />
•
<strong>看驱动代码</strong>：独立DMA控制器通常有专属驱动（如<code>drivers/dma/pl330.c</code>）。</p>
<hr />
<h3 id="总结-9"><strong>6. 总结</strong></h3>
<p>•
<strong>DMA可以是独立外设</strong>（如PL330），<strong>也可以是设备内置功能</strong>（如网卡DMA引擎）。<br />
•
<strong>操作系统通过统一API抽象差异</strong>，驱动无需关心底层硬件实现。<br />
• <strong>选择依赖场景</strong>：<br />
• 独立DMA：适合多外设共享的低速场景。<br />
• 集成DMA：适合高性能专用设备（如NVMe、GPU）。</p>
<p>通过这种分层设计，DMA在保证效率的同时，实现了硬件与软件的灵活解耦。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/linux/" class="category-chain-item">linux</a>
  
  
    <span>></span>
    
  <a href="/categories/linux/debug/" class="category-chain-item">debug</a>
  
  
    <span>></span>
    
  <a href="/categories/linux/debug/grub/" class="category-chain-item">grub</a>
  
  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Linux/" class="print-no-link">#Linux</a>
      
        <a href="/tags/qemu/" class="print-no-link">#qemu</a>
      
        <a href="/tags/linux/" class="print-no-link">#linux</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>grub中iommu=pt的作用</div>
      <div>https://realwujing.github.io/linux/debug/grub/grub中iommu=pt的作用/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Wu Jing</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年4月18日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/linux/debug/grub/grub%E4%B8%ADvmlinuz%20initramfs%E5%88%86%E6%9E%90/" title="grub中vmlinuz initramfs分析">
                        <span class="hidden-mobile">grub中vmlinuz initramfs分析</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"c11f8471a6ae4d3eea12","clientSecret":"87bfa232882af2b005f4c3352132dd418bf6d113","repo":"realwujing.github.io","owner":"realwujing","admin":["realwujing"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":false,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},
          {
            id: '70bb07480bf240c057e9e34abef1c72a'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
